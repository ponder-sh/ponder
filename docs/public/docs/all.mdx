---
title: "Integrate with Foundry"
description: "A guide for using Ponder with the Foundry smart contract development toolchain."
---

import { Callout, Steps } from "nextra/components";

# Foundry

This guide describes how to integrate Ponder and Foundry during local development.

Foundry projects follow various development workflows (test-driven, deploy to a fresh chain, deploy to a fork, etc). Rather than a one-size-fits-all integration, this page offers patterns that you can adapt to your workflow.

## Configure the `anvil` network

### Disable caching

Ponder's RPC request cache works well for live networks where the chain is generally immutable, but causes issues when indexing a local chain that "resets".

Use the `disableCache` option to **disable RPC request caching** for the Anvil network. With this option set to true, Ponder will clear the cache on start up and between hot reloads.

```ts filename="ponder.config.ts" {9}
import { createConfig } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: {
    anvil: {
      chainId: 31337,
      transport: http("http://127.0.0.1:8545"),
      disableCache: true,
    },
  },
  // ...
});
```

### Chain ID

We recommend using `31337` (the default Anvil chain ID) even when forking a live chain. This avoids common footguns when working with multiple networks.

### Mining mode

We recommend using [interval mining](https://book.getfoundry.sh/reference/anvil/#mining-modes) with a block time of ~2 seconds. This better simulates a live network.

<Callout type="warning">
  Known issue: When indexing Anvil with auto mining enabled in an app with
  multiple networks, indexing progress will get "stuck" at the timestamp of the
  latest Anvil block.{" "}
</Callout>

## Generate ABI files

To enable end-to-end type safety, the contract ABIs generated by Foundry must be copied into TypeScript (`.ts`) source files.

### Wagmi CLI

The Wagmi CLI [Foundry plugin](https://wagmi.sh/cli/api/plugins/foundry) is an excellent tool to automate tedious ABI file management. For more information, visit the [Wagmi CLI documentation](https://wagmi.sh/cli/getting-started).

Here is the Wagmi CLI config file used by the Foundry [example project](https://github.com/ponder-sh/ponder/tree/main/examples/with-foundry).

```ts filename="wagmi.config.ts"
import { defineConfig } from "@wagmi/cli";
import { foundry } from "@wagmi/cli/plugins";

export default defineConfig({
  out: "abis/CounterAbi.ts",
  plugins: [
    foundry({
      project: "foundry",
      include: ["Counter.sol/**"],
    }),
  ],
});
```

## Import broadcast files

Foundry scripts write transaction inputs and receipts to JSON files in the `broadcast` directory. You can import these files directly into `ponder.config.ts` to automate address management and enable hot reloading.

<Callout type="info">
  Remember to enable
  [broadcast](https://book.getfoundry.sh/tutorials/solidity-scripting?highlight=deploy#deploying-locally)
  so that `forge script` submits transactions to Anvil.
</Callout>

### Automate address management

To read the contract address and deployment block number from a broadcast file, import the file directly into `ponder.config.ts` and access properties from the JSON object.

The `ponder.config.ts` file from the Foundry [example project](https://github.com/ponder-sh/ponder/tree/main/examples/with-foundry) demonstrates this pattern. Here, the first transaction in the broadcast file deployed the `Counter.sol` contract. The location of the contract address and start block within the broadcast file depends on the order and number of transactions in your deployment script.

```ts filename="ponder.config.ts" {4, 6-7, 21-22}
import { createConfig } from "ponder";
import { http, getAddress, hexToNumber } from "viem";
import { counterABI } from "../abis/CounterAbi";
import CounterDeploy from "../foundry/broadcast/Deploy.s.sol/31337/run-latest.json";

const address = getAddress(CounterDeploy.transactions[0]!.contractAddress);
const startBlock = hexToNumber(CounterDeploy.receipts[0]!.blockNumber);

export default createConfig({
  networks: {
    anvil: {
      chainId: 31337,
      transport: http("http://127.0.0.1:8545"),
      disableCache: true,
    },
  },
  contracts: {
    Counter: {
      network: "anvil",
      abi: counterABI,
      address,
      startBlock,
    },
  },
});
```

### Enable hot reloading

If you import a JSON broadcast file in `ponder.config.ts`, the dev server will reload each time that file changes. This is a simple way to ensure that Ponder reloads every time you run a Foundry deployment script.

```ts filename="ponder.config.ts" {3-4}
import { createConfig } from "ponder";
import { http } from "viem";
import CounterDeploy from "../foundry/broadcast/Deploy.s.sol/31337/run-latest.json";
// ^ The development server detects changes to this file and triggers a hot reload.

export default createConfig({
  // ...
});
```

---
title: "Telemetry"
description: "An overview of how Ponder collects and uses telemetry."
---

import { Callout } from "nextra/components";

# Telemetry

Ponder collects **completely anonymous** telemetry data about general usage. The developers use this data to prioritize new feature development, identify bugs, and improve performance & stability.

## Opt out

To opt out of telemetry, set the `PONDER_TELEMETRY_DISABLED` environment variable.

{/* prettier-ignore */}
```js filename=".env.local"
PONDER_TELEMETRY_DISABLED = true
```

## Implementation

Ponder's telemetry implementation is 100% open-source. The [telemetry service](https://github.com/ponder-sh/ponder/blob/main/packages/core/src/common/telemetry.ts#L47) (part of `ponder`) runs on the user's device and submits event data via HTTP POST requests to the [telemetry collection endpoint](https://github.com/ponder-sh/ponder/blob/main/docs/pages/api/telemetry/index.ts) hosted at `https://ponder.sh/api/telemetry`.

The implementation generates a stable anonymous unique identifier for the user's device and stores it at the [system default user config directory](https://github.com/sindresorhus/env-paths#pathsconfig). This config also stores the user's opt-out preference and a stable salt used to hash potentially sensitive data such as file paths and the git remote URL.

---
title: "Logging"
description: "An overview of how to configure the Ponder logger."
---

import { Callout } from "nextra/components";

# Logging

Ponder produces logs to help you understand and debug your application.

![Dev server logs screenshot](/logs.gif)

<div className="caption">Dev server terminal UI (v0.0.75).</div>

## Log level

There are two ways to configure the minimum log level. If specified, the environment variable takes precedence over the CLI flag.

- Set the `PONDER_LOG_LEVEL` environment variable
- Use the `--log-level <LEVEL>`, `-v` (debug) or `-vv` (trace) CLI option

<div className="code-columns">

{/* prettier-ignore */}
```js filename=".env.local"
PONDER_LOG_LEVEL=trace
```

{/* prettier-ignore */}
```bash filename="bash"
ponder dev --log-level warn
# or, use the shortcut flag for debug
ponder dev -v
```

</div>

### Levels

| Log level        | Example                                           |
| :--------------- | :------------------------------------------------ |
| `silent`         |                                                   |
| `error`          | Unrecoverable RPC error, SQL constraint violation |
| `warn`           | Reorg reconciliation, malformed config            |
| `info` (default) | Indexing progress, real-time block processing     |
| `debug`          | Internal service lifecycle events                 |
| `trace`          | Query-level database logs                         |

### User logs

Logs produced by your code (e.g. `console.log` statements in `ponder.config.ts` or indexing functions) will always be written to the console. Note that Ponder _does_ catch **errors** thrown by your code and emits an `error` log including the original error message and stack trace.

## Log format

Use the `--log-format <FORMAT>` CLI option to set the log format.

<Callout type="info">The auto-updating terminal UI is always enabled during development (`ponder dev`) regardless of the log level or format.</Callout>

### Pretty (default)

{/* prettier-ignore */}
```bash filename="bash"
ponder start --log-format pretty
```

```bash filename="bash"
11:54:36 AM INFO  build      Using PGlite database at .ponder/pglite (default)
11:54:36 AM INFO  database   Created table 'Account' in 'public.db'
11:54:36 AM INFO  server     Started listening on port 42069
11:54:36 AM INFO  historical Started syncing 'optimism' logs for 'weth9' with 0.0% cached
11:54:36 AM INFO  historical Started syncing 'base' logs for 'weth9' with 0.0% cached
11:54:36 AM INFO  historical Started syncing 'polygon' logs for 'weth9' with 0.0% cached
```


### JSON

```bash filename="bash"
ponder start --log-format json
```

The JSON log format emits newline-delimited JSON objects with properties `level`, `time`, `service`, `msg`, and (optionally) `error`.

```json filename="bash"
{"level":30,"time":1717170664426,"service":"build","msg":"Using PGlite database at .ponder/pglite (default)"}
{"level":30,"time":1717170664454,"service":"database","msg":"Created table 'Account' in 'public.db'"}
{"level":30,"time":1717170664458,"service":"server","msg":"Started listening on port 42069"}
{"level":30,"time":1717170664625,"service":"historical","msg":"Started syncing 'base' logs for 'weth9' with 0.0% cached"}
{"level":30,"time":1717170664628,"service":"historical","msg":"Started syncing 'optimism' logs for 'weth9' with 0.0% cached"}
{"level":30,"time":1717170664683,"service":"historical","msg":"Started syncing 'polygon' logs for 'weth9' with 0.0% cached"}
```
---
title: "Metrics"
description: "An overview of the metrics that Ponder exposes."
---

import { Callout } from "nextra/components";

# Metrics üöß

This page is under construction.

<Callout type="warning">
  Metrics are not part of the public API, so these are subject to change without
  notice. Do not rely on these metrics for anything important (yet).
</Callout>

Ponder apps publish Prometheus metrics at the `/metrics` path.

| name                                   | description                                                           | type      |
| :------------------------------------- | :-------------------------------------------------------------------- | --------- |
| ponder_indexing_total_seconds          | Total number of seconds required for indexing                         | gauge     |
| ponder_indexing_completed_seconds      | Number of seconds that have been completed                            | gauge     |
| ponder_indexing_completed_events       | Number of events that have been processed                             | gauge     |
| ponder_indexing_completed_timestamp    | Timestamp through which all events have been completed                | gauge     |
| ponder_indexing_has_error              | Boolean (0 or 1) indicating if there is an indexing error             | gauge     |
| ponder_indexing_function_duration      | Duration of indexing function execution                               | histogram |
| ponder_indexing_function_error_total   | Total number of errors encountered during indexing function execution | counter   |
| ponder_historical_start_timestamp      | Unix timestamp (ms) when the historical sync service started          | gauge     |
| ponder_historical_total_blocks         | Number of blocks required for the historical sync                     | gauge     |
| ponder_historical_cached_blocks        | Number of blocks that were found in the cache for the historical sync | gauge     |
| ponder_historical_completed_blocks     | Number of blocks that have been processed for the historical sync     | gauge     |
| ponder_realtime_is_connected           | Boolean (0 or 1) indicating if the realtime sync service is connected | gauge     |
| ponder_realtime_latest_block_number    | Block number of the latest synced block                               | gauge     |
| ponder_realtime_latest_block_timestamp | Block timestamp of the latest synced block                            | gauge     |
| ponder_realtime_reorg_total            | Count of how many re-orgs have occurred                               | counter   |
| ponder_database_method_duration        | Duration of database operations                                       | histogram |
| ponder_database_method_error_total     | Total number of errors encountered during database operations         | counter   |
| ponder_http_server_port                | Port that the server is listening on                                  | gauge     |
| ponder_http_server_active_requests     | Number of active HTTP server requests                                 | gauge     |
| ponder_http_server_request_duration_ms | Duration of HTTP responses served by the server                       | histogram |
| ponder_http_server_request_size_bytes  | Size of HTTP requests received by the server                          | histogram |
| ponder_http_server_response_size_bytes | Size of HTTP responses served by the server                           | histogram |
| ponder_rpc_request_duration            | Duration of RPC requests                                              | histogram |
| ponder_rpc_request_lag                 | Time RPC requests spend waiting in the request queue                  | histogram |
| ponder_postgres_pool_connections       | Gauge of current connections for PostgreSQL pools                     | gauge     |
| ponder_postgres_query_queue_size       | Current size of the query queue for PostgreSQL                        | gauge     |
| ponder_postgres_query_total            | Total number of queries processed by PostgreSQL                       | counter   |

---
title: "Status"
description: "An overview of the indexing status data that Ponder exposes."
---

import { Callout } from "nextra/components";

# Status

To check the indexing status of your app, use the `/status` endpoint or the `_meta` field in the GraphQL API.

## Usage

Use the indexing status to quickly confirm that Ponder is working as expected. You can also poll the status to confirm that a specific block number has been ingested by Ponder before refetching a query client-side (for example, in a form submit handler).

### HTTP

<div className="code-columns">

```bash filename="Request"
curl http://localhost:42069/status
```

```json filename="Response"
{
  "mainnet": {
    "ready": true,
    "block": {
      "number": 20293450,
      "timestamp": 1720823759
    }
  },
  "base": {
    "ready": true,
    "block": {
      "number": 17017206,
      "timestamp": 1720823759
    }
  }
}
```

</div>

### GraphQL

<div className="code-columns">

```graphql filename="Query"
query {
  _meta {
    status
  }
}
```

```json filename="Result"
{
  "_meta": {
    "status": {
      "mainnet": {
        "ready": true,
        "block": {
          "number": 20293464,
          "timestamp": 1720823939
        }
      },
      "base": {
        "ready": false,
        "block": null
      }
    }
  }
}
```

</div>

## API

The response object contains a property for each network in your app with the following fields.

| field     |                       type                       | description                                                                        |
| :-------- | :----------------------------------------------: | :--------------------------------------------------------------------------------- |
| **ready** |                    `boolean`                     | `true` if historical indexing is complete.                                         |
| **block** | `{ number: number; timestamp: number; } \| null` | The most recently indexed block, or `null` if historical indexing is not complete. |

---
title: "Block intervals"
description: "Learn how to index block intervals in a Ponder app"
---

import { Callout } from "nextra/components";

# Block intervals

To run indexing functions on a schedule, use a **block interval**. Block intervals are great for "cron" workloads, because they run at a consistent frequency regardless of contract activity or transactions.

This guide describes how to configure block intervals, and suggests patterns for common use cases. See also the `ponder.config.ts` [API reference](/docs/api-reference/config) page.

## Name

Every block interval must have a name, provided as a key to the `blocks` object. The name must be unique across `blocks` and `contracts`.

```ts filename="ponder.config.ts" {9}
import { createConfig } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  blocks: {
    ChainlinkOracleUpdate: {
      network: "mainnet",
      startBlock: 19783636,
      interval: 60 / 12, // Every 60 seconds
    },
  },
});
```

<details>
  <summary><p>Example block event indexing function</p></summary>
  <p />

This indexing function uses block events to index price chart data by reading the latest price from a Chainlink oracle contract every minute.

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";
import { prices } from "ponder:schema";
import { ChainlinkOracleAbi } from "../abis/ChainlinkOracle.ts";

ponder.on("ChainlinkOracleUpdate:block", async ({ event, context }) => {
  // Fetch the price at the current block height.
  const latestPrice = await client.readContract({
    abi: ChainlinkOracleAbi,
    address: "0xD10aBbC76679a20055E167BB80A24ac851b37056",
    functionName: "latestAnswer",
  });

  // Insert a row into the prices table.
  await context.db.insert(prices).values({
    id: event.block.timestamp,
    blockNumber: event.block.number,
    timestamp: event.block.timestamp,
    price: latestPrice,
  });
});
```

</details>

## Interval

The `interval` option specifies how often the indexing function should run. For example, a block interval with a start block of `100` and a interval of `10` will index blocks `100`, `110`, `120`, `130`, and so on.

### Block time

It's often easier to think about a time interval instead of a block interval. To convert between the two, divide the time interval by the network block time.

For example, if the network block time is 3 seconds and you want to run an indexing function once per day:

```ts
// 24 hours per day, 60 minutes per hour, 60 seconds per minute
const secondsInterval = 24 * 60 * 60;
// 3 seconds per block
const blockTime = 3;
// 28800 blocks per day
const blockInterval = secondsInterval / blockTime;
```

To find the block time of a specific chain, check the chain's documentation website or block explorer. Most Etherscan deployments have a [`/chart/blocktime`](https://polygonscan.com/chart/blocktime) page.

## Network

### Single network

If you only need to index blocks from one network, pass the network name as a string to the `network` field.

```ts filename="ponder.config.ts" {10}
import { createConfig } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  blocks: {
    ChainlinkOracleUpdate: {
      network: "mainnet",
      startBlock: 19783636,
      interval: 60 / 12, // Every 60 seconds
    },
  },
});
```

### Multiple networks

If you'd like to run the same block indexing function across multiple networks, pass an object to the `network` field containing network-specific options.

```ts filename="ponder.config.ts" {11-19}
import { createConfig } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
    optimism: { chainId: 10, transport: http(process.env.PONDER_RPC_URL_10) },
  },
  blocks: {
    ChainlinkOracleUpdate: {
      network: {
        mainnet: {
          startBlock: 19783636,
          interval: (60 * 60) / 12, // Every 60 minutes
        },
        optimism: {
          startBlock: 119534316,
          interval: (60 * 60) / 2, // Every 60 minutes
        },
      },
    },
  },
});
```

Now, the indexing functions you write for `ChainlinkOracleUpdate:block` will process blocks from both mainnet and Optimism.

The `context.network` object contains information about which network the current block is from.

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";

ponder.on("ChainlinkOracleUpdate:block", async ({ event, context }) => {
  context.network;
  //      ^? { name: "mainnet", chainId 1 } | { name: "optimism", chainId 10 }

  if (context.network.name === "mainnet") {
    // Do mainnet-specific stuff!
  }
});
```

Just like with contracts, you can use network-specific overrides for the `interval`, `startBlock` and `endBlock` options. Read more about [network-specific overrides](/docs/contracts-and-networks#network-override-logic).

## Block range

The optional `startBlock` and `endBlock` options specify the block range to index. The default value for `startBlock` is `0{:ts}`, and the default value for `endBlock` is `undefined{:ts}`. When `endBlock` is `undefined{:ts}`, Ponder will index the contract in realtime.

If `endBlock` is defined, no events will be indexed after that block number. This option is useful if you're only interested in a slice of historical data, or to enable faster feedback loops during development where it's not necessary to index the entire history.

```ts filename="ponder.config.ts" {9}
import { createConfig } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  blocks: {
    ChainlinkOracleUpdate: {
      network: "mainnet",
      interval: 60 / 12, // Every 60 seconds
      startBlock: 19600000,
      endBlock: 19700000,
    },
  },
});
```

---
title: "Contracts & networks"
description: "Learn how to add contracts and networks in ponder.config.ts"
---

import { Callout } from "nextra/components";

# Contracts & networks

To add a new contract to your app, use the `contracts` field in `ponder.config.ts`. For each contract you add, the sync engine will fetch raw blockchain data and pass that data to the indexing functions you write.

This guide explains how each contract configuration field works, and suggests patterns for common use cases. See also the `ponder.config.ts` [API reference](/docs/api-reference/config) page.

## Contract name

Every contract must have a unique name, provided as a key to the `contracts` object.

```ts filename="ponder.config.ts" {11}
import { createConfig } from "ponder";
import { http } from "viem";

import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
    },
  },
});
```

## ABI

Each contract must have an ABI.

The config uses ABIType to offer autocomplete and type checking. All ABIs should be saved in `.ts` files and include an `as const{:ts}` assertion. For more information, please reference the [ABIType documentation](https://abitype.dev/guide/getting-started#usage).

<div className="code-columns">

```ts filename="abis/Blitmap.ts" {11}
export const BlitmapAbi = [
  { inputs: [], stateMutability: "nonpayable", type: "constructor" },
  {
    inputs: [{ internalType: "address", name: "owner", type: "address" }],
    name: "balanceOf",
    outputs: [{ internalType: "uint256", name: "", type: "uint256" }],
    stateMutability: "view",
    type: "function",
  },
  // ...
] as const;
```

```ts filename="ponder.config.ts" {3, 9}
import { createConfig } from "ponder";

import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  // ...
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
    },
  },
});
```

</div>

### Multiple ABIs

It's occasionally useful to provide multiple ABIs for one contract, like when defining a proxy/upgradable contract that has gone through multiple implementation contracts. The [`mergeAbis`](/docs/utilities/abi) utility function safely removes duplicate ABI items and maintains strict types.

```ts filename="ponder.config.ts" {1,14}
import { createConfig, mergeAbis } from "ponder";
import { http } from "viem";

import { ERC1967ProxyAbi } from "./abis/ERC1967Proxy";
import { NameRegistryAbi } from "./abis/NameRegistry";
import { NameRegistry2Abi } from "./abis/NameRegistry2";

export default createConfig({
  networks: {
    goerli: { chainId: 5, transport: http(process.env.PONDER_RPC_URL_5) },
  },
  contracts: {
    FarcasterNameRegistry: {
      abi: mergeAbis([ERC1967ProxyAbi, NameRegistryAbi, NameRegistry2Abi]),
      network: "goerli",
      address: "0xe3Be01D99bAa8dB9905b33a3cA391238234B79D1",
      startBlock: 7648795,
    },
  },
});
```

## Network

### Single network

If the contract is only deployed to one network, just pass the network name as a string to the `network` field.

```ts filename="ponder.config.ts" {8,16}
import { createConfig } from "ponder";
import { http } from "viem";

import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  networks: {
    mainnet: {
      chainId: 1,
      transport: http(process.env.PONDER_RPC_URL_1),
    },
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04...D3Ff63",
      startBlock: 12439123,
    },
  },
});
```

### Multiple networks

If you'd like to index the same contract (having the same ABI) across multiple networks, pass an object to the `network` field containing network-specific options.

```ts filename="ponder.config.ts" {14-23}
import { createConfig } from "ponder";
import { http } from "viem";

import { UniswapV3FactoryAbi } from "./abis/UniswapV3Factory";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
    base: { chainId: 8453, transport: http(process.env.PONDER_RPC_URL_8453) },
  },
  contracts: {
    UniswapV3Factory: {
      abi: UniswapV3FactoryAbi,
      network: {
        mainnet: {
          address: "0x1F98431c8aD98523631AE4a59f267346ea31F984",
          startBlock: 12369621,
        },
        base: {
          address: "0x33128a8fC17869897dcE68Ed026d694621f6FDfD",
          startBlock: 1371680,
        },
      },
    },
  },
});
```

Now, the indexing functions you write for `UniswapV3Factory` will process events from both mainnet and Base.

The `event` and `context` objects are still strictly typed according to the configuration you provide. The `context.network` object contains information about which network the current event is from.

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";

ponder.on("UniswapV3Factory:Ownership", async ({ event, context }) => {
  context.network;
  //      ^? { name: "mainnet", chainId 1 } | { name: "base", chainId 8453 }

  event.log.address;
  //        ^? "0x1F98431c8aD98523631AE4a59f267346ea31F984" | "0x33128a8fC17869897dcE68Ed026d694621f6FDfD"

  if (context.network.name === "mainnet") {
    // Do mainnet-specific stuff!
  }
});
```

#### Network override logic

Network-specific configuration uses an override pattern. Any options defined at the top level are the default, and the network-specific objects override those defaults. All fields other than `abi` can be specified on a per-network basis, including `address`, `filter`, `startBlock`, and `endBlock`.

For example, the Uniswap V3 factory contract is deployed to the same address on most chains, but has a different address on Base.

```ts filename="ponder.config.ts"
import { createConfig } from "ponder";
import { http } from "viem";

import { UniswapV3FactoryAbi } from "./abis/EntryPoint";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
    optimism: { chainId: 10, transport: http(process.env.PONDER_RPC_URL_10) },
    base: { chainId: 8453, transport: http(process.env.PONDER_RPC_URL_8453) },
  },
  contracts: {
    UniswapV3Factory: {
      abi: UniswapV3FactoryAbi,
      address: "0x1F98431c8aD98523631AE4a59f267346ea31F984",
      network: {
        // No network-specific address provided for mainnet and Optimism.
        // The default address will be used ("0x1F98431c8aD98523631AE4a59f267346ea31F984").
        mainnet: { startBlock: 12369621 },
        optimism: { startBlock: 0 },
        // The network-specific address will be used ("0x33128a8fC17869897dcE68Ed026d694621f6FDfD").
        base: {
          address: "0x33128a8fC17869897dcE68Ed026d694621f6FDfD",
          startBlock: 1371680,
        },
      },
    },
  },
});
```

On the other hand, the ERC-4337 Entry Point contract is deployed to the same address on all networks, so you could define the `address` field at the top level.

```ts filename="ponder.config.ts"
import { createConfig } from "ponder";
import { http } from "viem";

import { EntryPointAbi } from "./abis/EntryPoint";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
    optimism: { chainId: 10, transport: http(process.env.PONDER_RPC_URL_10) },
  },
  contracts: {
    EntryPoint: {
      abi: EntryPointAbi,
      address: "0x1F98431c8aD98523631AE4a59f267346ea31F984",
      network: {
        mainnet: { startBlock: 12369621 },
        optimism: { startBlock: 88234528 },
      },
    },
  },
});
```

## Address

### Single address

The simplest (and most common) option is to pass a single static address.

```ts filename="ponder.config.ts" {14}
import { createConfig } from "ponder";
import { http } from "viem";

import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
    },
  },
});
```

### Multiple addresses

The `address` field also accepts a list of contract addresses.

This option can be used to index multiple contracts with known addresses that have the same ABI (or share an interface, like ERC721) using the same indexing functions.

<Callout type="info">
  When using this option, `startBlock` is shared across all addresses. It's
  often best to use the earliest deployment block among them.
</Callout>

```ts filename="ponder.config.ts" {14-19}
import { createConfig } from "ponder";
import { http } from "viem";

import { ERC721Abi } from "./abis/ERC721";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  contracts: {
    NiceJpegs: {
      abi: ERC721Abi,
      network: "mainnet",
      address: [
        "0x4E1f41613c9084FdB9E34E11fAE9412427480e56", // Terraforms
        "0xBC4CA0EdA7647A8aB7C2061c2E118A18a936f13D", // BAYC
        "0x8a90CAb2b38dba80c64b7734e58Ee1dB38B8992e", // Doodles
        "0x0000000000664ceffed39244a8312bD895470803", // !fundrop
      ],
      startBlock: 12439123,
    },
  },
});
```

### Factory contracts

The `factory()` function is used to specify a set of contracts that are created by a factory.

```ts filename="ponder.config.ts" {12-19}
import { createConfig, factory } from "ponder";
import { parseAbiItem } from "viem";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  contracts: {
    SudoswapPool: {
      abi: SudoswapPoolAbi,
      network: "mainnet",
      address: factory({
        // The address of the factory contract that creates instances of this child contract.
        address: "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4",
        // The event emitted by the factory that announces a new instance of this child contract.
        event: parseAbiItem("event NewPair(address poolAddress)"),
        // The name of the parameter that contains the address of the new child contract.
        parameter: "poolAddress",
      }),
      startBlock: 14645816,
    },
  },
});
```

Now, the indexing functions you write for `SudoswapPool` will process events emitted by all child contracts that are created by the specified factory. The `event.log.address` field contains the address of the child contract that emitted the current event.

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";

ponder.on("SudoswapPool:Transfer", async ({ event }) => {
  // This is the address of the child contract that emitted the event.
  event.log.address;
  //        ^? string
});
```

To run an indexing function whenever a child contract is created (but before any of its events are indexed), add a new contract to your config that uses the factory contract in the `address` field.

<div className="code-columns">

```ts filename="ponder.config.ts" {9-14}
import { createConfig, factory } from "ponder";
import { parseAbiItem } from "viem";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  contracts: {
    SudoswapFactory: {
      abi: SudoswapFactoryAbi,
      network: "mainnet",
      address: "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4",
      startBlock: 14645816,
    },
    SudoswapPool: {
      abi: SudoswapPoolAbi,
      network: "mainnet",
      address: factory({
        address: "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4",
        event: parseAbiItem("event NewPair(address poolAddress)"),
        parameter: "poolAddress",
      }),
      startBlock: 14645816,
    },
  },
});
```

```ts filename="src/index.ts" {3-8}
import { ponder } from "ponder:registry";

// This function will run whenever a new child contract is created.
ponder.on("SudoswapFactory:NewPair", async ({ event }) => {
  // Address of the child contract that was created.
  event.args.poolAddress;
  //        ^? string
});

ponder.on("SudoswapPool:Transfer", async ({ event }) => {
  // Address of the child contract that emitted the event.
  event.log.address;
  //        ^? string
});
```

</div>

**Multiple factory contracts create the same child contract**

The factory `address` field also accepts a list of factory contract addresses. Use this option if there are multiple factory contracts on the same network that have the same ABI, factory event signature, and create the same kind of child contract.

```ts filename="ponder.config.ts" {12-15}
import { createConfig } from "ponder";
import { parseAbiItem } from "viem";

export default createConfig({
  // ...
  contracts: {
    SudoswapPool: {
      abi: SudoswapPoolAbi,
      network: "mainnet",
      address: factory({
        // A list of factory contract addresses that all create SudoswapPool contracts.
        address: [
          "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4",
          "0xb16c1342E617A5B6E4b631EB114483FDB289c0A4",
        ],
        event: parseAbiItem("event NewPair(address poolAddress)"),
        parameter: "poolAddress",
      }),
    },
  },
});
```

**Factory contract requirements & limitations**

1. **Event signature requirements**: The factory contract must emit an event log announcing the creation of each new child contract that contains the new child contract address as a named parameter (with type `"address"`). The parameter can be either indexed or non-indexed. Here are a few factory event signatures with their eligibility explained:

```solidity
// ‚úÖ Eligible. The parameter "child" has type "address" and is non-indexed.
event ChildContractCreated(address child);

// ‚úÖ Eligible. The parameter "pool" has type "address" and is indexed.
event PoolCreated(address indexed deployer, address indexed pool, uint256 fee);

// ‚ùå Ineligible. The parameter "contracts" is an array type, which is not supported.
// Always emit a separate event for each child contract, even if they are created in a batch.
event ContractsCreated(address[] contracts);

// ‚ùå Ineligible. The parameter "child" is a struct/tuple, which is not supported.
struct ChildContract {
  address addr;
}
event ChildCreated(ChildContract child);
```

2. **Nested factory patterns**: The sync engine doesn't support factory patterns that are nested beyond a single layer.

3. **Scaling**: The sync engine supports any number of child contracts. If a factory contract has more than 1,000 children, the sync engine omits the `address` argument when calling `eth_getLogs` or `trace_filter` and filters the result client-side. This can cause slow sync performance for very large factories.

### Proxy & upgradable contracts

To index a proxy/upgradable contract, use the proxy contract address in the `address` field. Then, be sure to include the ABIs of all implementation contracts that the proxy has ever had. The implementation ABIs are required to properly identify and decode all historical event logs. To add multiple ABIs safely, use the [`mergeAbis`](/docs/utilities/abi) utility function.

<Callout>
Tip: On Etherscan, there is a link to the current implementation contract on the **Contract ‚Üí Read as Proxy** tab. You can copy all the implementation ABIs as text and paste them into `.ts` files.

![Etherscan contract proxy address](/etherscan-proxy-contract.png)

</Callout>

## Event filter

The `filter` option filters for events by signature and indexed argument values. This makes it possible to index events emitted by _any contract on the network_ that match the specified signature and arguments.

### By event name or signature

The `filter.event` option accepts an event name (or list of event names) present in the provided ABI.

```ts filename="ponder.config.ts" {14}
import { createConfig } from "ponder";
import { http } from "viem";

import { ERC20Abi } from "./abis/ERC20";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  contracts: {
    ERC20: {
      abi: ERC20Abi,
      network: "mainnet",
      filter: { event: "Transfer" },
      //        ^? "Transfer" | "Approval" | ("Transfer" | "Approval")[]
      startBlock: 18500000,
      endBlock: 18505000,
    },
  },
});
```

The indexing functions you write will run for all events matching the filter, regardless of which contract emitted them.

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";

ponder.on("ERC20:Transfer", async ({ event }) => {
  // This is the address of the contract that emitted the event.
  // With this config, it could be any ERC20 contract on mainnet.
  event.log.address;
  //        ^? string
});
```

### By indexed argument value

You can use the `filter.event` and `filter.args` options together to filter for events that have specific indexed argument values. Each indexed argument field accepts a single value or a list of values to match.

This example filters for all ERC20 `Transfer` events where the `from` argument matches a specific address, and the `to` argument matches one of two addresses.

```ts filename="ponder.config.ts" {14-23}
import { createConfig } from "ponder";
import { http } from "viem";

import { ERC20Abi } from "./abis/ERC20";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  contracts: {
    ERC20: {
      abi: ERC20Abi,
      network: "mainnet",
      filter: {
        event: "Transfer",
        args: {
          from: "0xa0ee7a142d267c1f36714e4a8f75612f20a79720",
          to: [
            "0x06012c8cf97bead5deae237070f9587f8e7a266d",
            "0x7c40c393dc0f283f318791d746d894ddd3693572",
          ],
        },
      },
      startBlock: 18500000,
      endBlock: 18505000,
    },
  },
});
```

The indexing function will run for all events matching the filter.

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";

ponder.on("ERC20:Transfer", async ({ event }) => {
  // This will always be "0xa0ee7a142d267c1f36714e4a8f75612f20a79720"
  event.args.from;
  // This will be one of the two addresses above
  event.args.to;
});
```

## Call traces

The `includeCallTraces{:ts}` option specifies whether to enable call trace indexing for a contract. By default, call traces are **disabled**.

After enabling this option, each function in the contract ABI will become available as an indexing function event name. [Read more](/docs/indexing/call-traces) about call traces.

<div className="code-columns">

```ts filename="ponder.config.ts" {11}
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
      includeCallTraces: true,
    },
  },
  // ...
});
```

```ts filename="src/index.ts" {15}
import { ponder } from "ponder:registry";

ponder.on("Blitmap.mintOriginal()", async ({ event }) => {
  event.args;
  //    ^? [tokenData: Hex, name: string]
  event.trace.gasUsed;
  //          ^? bigint
});
```

</div>

## Transaction receipts

The `includeTransactionReceipts{:ts}` option specifies whether to include the transaction receipt. By default, transaction receipts are **disabled**.

After enabling this option, the `event.transactionReceipt{:ts}` property will become available in all indexing functions for the contract. To see all fields available on the receipt object, [read the API reference](/docs/api-reference/indexing-functions#transaction-receipt).

<div className="code-columns">

```ts filename="ponder.config.ts" {11}
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
      includeTransactionReceipts: true,
    },
  },
  // ...
});
```

```ts filename="src/index.ts" {15}
import { ponder } from "ponder:registry";

ponder.on("Blitmap.mintOriginal()", async ({ event }) => {
  event.transactionReceipt.cumulativeGasUsed;
  //                       ^? bigint
  event.transactionReceipt.logs;
  //                       ^? Log[]
});
```

</div>

## Block range

The optional `startBlock` and `endBlock` options specify the block range to index.

| Option       | Default          |
| :----------- | :--------------- |
| `startBlock` | `0{:ts}`         |
| `endBlock`   | `undefined{:ts}` |

If `endBlock` is `undefined{:ts}`, the contract will be indexed in realtime. If `endBlock` is defined, no events will be indexed after that block. This option can be useful if you're only interested in a slice of historical data, or to enable faster feedback loops during development where it's not necessary to index the entire history.

```ts filename="ponder.config.ts" {15-16}
import { createConfig } from "ponder";
import { http } from "viem";

import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
      endBlock: 16500000,
    },
  },
});
```

---
title: "API Reference: ponder.config.ts"
description: "Learn about the options available in ponder.config.ts, Ponder's config file."
---

import { Callout, Tabs } from "nextra/components";

# Config API

The `ponder.config.ts` file contains contract names, addresses, and ABIs; network information like chain IDs and RPC URLs; database configuration; and general options.

## File requirements

The `ponder.config.ts` file must **default export** the object returned by `createConfig`.

{/* prettier-ignore */}
```ts filename="ponder.config.ts" {1,4}
import { createConfig } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: { /* ... */ },
  contracts: { /* ... */ },
});
```

By default, `ponder dev` and `start` look for `ponder.config.ts` in the current working directory. Use the `--config-file` CLI option to specify a different path.

## Networks

The `networks` field is an object where each key is a network name containing that network's configuration. Networks are Ethereum-based blockchains like Ethereum mainnet, Goerli, or Foundry's local Anvil node.

<Callout type="warning">
  Most Ponder apps require a paid RPC provider plan to avoid rate-limiting.
</Callout>

| field                    |          type          |                                                                                                                            |
| :----------------------- | :--------------------: | :------------------------------------------------------------------------------------------------------------------------- |
| **name**                 |        `string`        | A unique name for the blockchain. Must be unique across all networks. _Provided as an object property name._               |
| **chainId**              |        `number`        | The [chain ID](https://chainlist.org) for the network.                                                                     |
| **transport**            |    `viem.Transport`    | A Viem `http`, `webSocket`, or `fallback` [Transport](https://viem.sh/docs/clients/transports/http.html).                  |
| **pollingInterval**      | `number \| undefined`  | **Default: `1_000`**. Frequency (in ms) used when polling for new events on this network.                                  |
| **maxRequestsPerSecond** | `number \| undefined`  | **Default: `50`**. Maximum number of RPC requests per second. Can be reduced to work around rate limits.                   |
| **disableCache**         | `boolean \| undefined` | **Default: `false`**. Disables the RPC request cache. Use when indexing a [local node](/docs/advanced/foundry) like Anvil. |

```ts filename="ponder.config.ts" {7-12,16}
import { createConfig } from "ponder";
import { http } from "viem";

import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  networks: {
    mainnet: {
      chainId: 1,
      transport: http(process.env.PONDER_RPC_URL_1),
    },
  },
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
    },
  },
});
```

## Contracts

<Callout>
  This is a low-level API reference. For an approachable overview & recipes, see
  the [contracts & networks](/docs/contracts-and-networks) guide.
</Callout>

The `contracts` field is an object where each key is a contract name containing that contract's configuration. Ponder will sync & index logs or call traces according to the options you provide.

| field                          |                         type                         |                                                                                                                                                                                                                          |
| :----------------------------- | :--------------------------------------------------: | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **name**                       |                       `string`                       | A unique name for the smart contract. Must be unique across all contracts. _Provided as an object property name._                                                                                                        |
| **abi**                        |                    `abitype.Abi`                     | The contract [ABI](https://docs.soliditylang.org/en/v0.8.17/abi-spec.html) as an array as const. Must be asserted as constant, see [ABIType documentation](https://abitype.dev/guide/getting-started#usage) for details. |
| **network**                    |                       `string`                       | The name of the network this contract is deployed to. References the `networks` field. Also supports [multiple networks](/docs/contracts-and-networks#multiple-networks).                                                |
| **address**                    | `0x{string} \| 0x{string}[] \| Factory \| undefined` | One or more contract addresses or factory configuration.                                                                                                                                                                 |
| **filter**                     |                 [`Filter`](#filter)                  | Event filter criteria.                                                                                                                                                                                                   |
| **startBlock**                 |                `number \| undefined`                 | **Default: `0`**. Block number to start syncing events. Usually set to the contract deployment block number.                                                                                                             |
| **endBlock**                   |                `number \| undefined`                 | **Default: `undefined`**. Block number to stop syncing events. If this field is specified, the contract will not be indexed in realtime. This field can be used alongside `startBlock` to index a specific block range.  |
| **includeTransactionReceipts** |                `boolean \| undefined`                | **Default: `false`**. If this field is `true`, `transactionReceipt` will be included in `event`.                                                                                                                         |
| **includeCallTraces**          |                `boolean \| undefined`                | **Default: `false`**. If this field is `true`, each function in the abi will be available as an indexing function event name. See the [call traces guide](/docs/call-traces#register-an-indexing-function) for details.  |

```ts filename="ponder.config.ts" {7-14}
import { createConfig } from "ponder";

import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  // ... more config
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
    },
  },
});
```

### Filter

| field     |               type                |                                                                                                                                                   |
| :-------- | :-------------------------------: | :------------------------------------------------------------------------------------------------------------------------------------------------ |
| **event** | `string \| string[] \| undefined` | **Default: `undefined`**. One or more event names present in the provided ABI.                                                                    |
| **args**  |       `object \| undefined`       | **Default: `undefined`**. An object containing indexed argument values to filter for. Only allowed if **one** event name was provided in `event`. |

[Read more](/docs/contracts-and-networks#event-filter) about event filters.

## Accounts

The `accounts` field is an object similar to `contracts` where each key is an account name containing that account's configuration. Accounts are used to index transactions or native transfers.

| field                          |                         type                         |                                                                                                                                                                                                                         |
| :----------------------------- | :--------------------------------------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **name**                       |                       `string`                       | A unique name for the smart contract. Must be unique across all contracts. _Provided as an object property name._                                                                                                       |
| **network**                    |                       `string`                       | The name of the network this contract is deployed to. References the `networks` field. Also supports [multiple networks](/docs/contracts-and-networks#multiple-networks).                                               |
| **address**                    | `0x{string} \| 0x{string}[] \| Factory \| undefined` | Address or factory configuration.                                                                                                                                                                                       |
| **startBlock**                 |                `number \| undefined`                 | **Default: `0`**. Block number to start syncing events.                                                                                                                                                                 |
| **endBlock**                   |                `number \| undefined`                 | **Default: `undefined`**. Block number to stop syncing events. If this field is specified, the contract will not be indexed in realtime. This field can be used alongside `startBlock` to index a specific block range. |
| **includeTransactionReceipts** |                `boolean \| undefined`                | **Default: `false`**. If this field is `true`, `transactionReceipt` will be included in `event`.                                                                                                                        |

```ts filename="ponder.config.ts" {5-11}
import { createConfig } from "ponder";

export default createConfig({
  // ... more config
  accounts: {
    coinbasePrime: {
      network: "mainnet",
      address: "0xCD531Ae9EFCCE479654c4926dec5F6209531Ca7b",
      startBlock: 12111233,
    },
  },
});
```

## Blocks

```ts filename="ponder.config.ts" {5-11}
import { createConfig } from "ponder";

export default createConfig({
  // ... more config
  blocks: {
    ChainlinkPriceOracle: {
      network: "mainnet",
      startBlock: 19_750_000,
      interval: 5, // every minute
    },
  },
});
```

## `factory()`

The `factory()` function is used to specify if an address is derived from the log of another contract. Both [`contracts`](#contracts) and [`accounts`](#accounts) support `factory()` in their `address` field.

| field         |                         type                         |                                                                                               |
| :------------ | :--------------------------------------------------: | :-------------------------------------------------------------------------------------------- |
| **address**   |             `0x{string} \| 0x{string}[]`             | The address of the factory contract that creates instances of this contract.                  |
| **event**     | [`AbiEvent`](https://abitype.dev/api/types#abievent) | The ABI item of the event that announces the creation of a new child contract.                |
| **parameter** |                       `string`                       | The name of the parameter within `event` that contains the address of the new child contract. |

[Read more](/docs/contracts-and-networks#factory-contracts) about factory patterns.

```ts filename="ponder.config.ts" {8-14}
import { createConfig, factory } from "ponder";

export default createConfig({
  // ... more config
  contracts: {
    uniswapV2: {
      // ... other contract options
      address: factory({
        address: "0x5C69bEe701ef814a2B6a3EDD4B1652CB9cc5aA6f",
        event: parseAbiItem(
          "event PairCreated(address indexed token0, address indexed token1, address pair, uint256)"
        ),
        parameter: "pair",
      }),
    },
  },
});
```

## Database

Here is the logic Ponder uses to determine which database to use:

- If the `database.kind` option is specified, use the specified database.
- If the `DATABASE_URL` environment variable is defined, use Postgres with that connection string.
- If `DATABASE_URL` is not defined, use PGlite.

### PGlite

| field         |         type          |                                                                                 |
| :------------ | :-------------------: | :------------------------------------------------------------------------------ |
| **kind**      |      `"pglite"`       |                                                                                 |
| **directory** | `string \| undefined` | **Default: `.ponder/pglite`**. Directory path to use for PGlite database files. |

<details>
  <summary><p>Example `ponder.config.ts` using PGlite</p></summary>
  <p />

```ts filename="ponder.config.ts" {4-7}
import { createConfig } from "ponder";

export default createConfig({
  database: {
    kind: "pglite",
    directory: "./.ponder/pglite",
  },
  // ... more config
});
```

</details>

### Postgres

| field                |                                type                                |                                                                           |
| :------------------- | :----------------------------------------------------------------: | :------------------------------------------------------------------------ |
| **kind**             |                            `"postgres"`                            |                                                                           |
| **connectionString** |                       `string \| undefined`                        | **Default: `DATABASE_URL` env var**. Postgres database connection string. |
| **poolConfig**       | [`PoolConfig`](https://node-postgres.com/apis/pool) \| `undefined` | **Default: `{ max: 30 }`**. Pool configuration passed to `node-postgres`. |

<details>
  <summary><p>Example `ponder.config.ts` using Postgres</p></summary>
  <p />

```ts filename="ponder.config.ts" {4-10}
import { createConfig } from "ponder";

export default createConfig({
  database: {
    kind: "postgres",
    connectionString: "postgresql://user:password@localhost:5432/dbname",
    poolConfig: {
      max: 100,
    },
  },
  // ... more config
});
```

</details>

## Examples

### Basic example

```ts filename="ponder.config.ts"
import { createConfig } from "ponder";
import { http } from "viem";

import { ArtGobblersAbi } from "./abis/ArtGobblers";

export default createConfig({
  networks: {
    mainnet: {
      chainId: 1,
      transport: http(process.env.PONDER_RPC_URL_1),
    },
  },
  contracts: {
    ArtGobblers: {
      network: "mainnet",
      abi: ArtGobblersAbi,
      address: "0x60bb1e2aa1c9acafb4d34f71585d7e959f387769",
      startBlock: 15863321,
    },
  },
});
```

### Using top-level await

{/* prettier-ignore */}
```ts filename="ponder.config.ts" {5,19}
import { createConfig } from "ponder";

import { ArtGobblersAbi } from "./abis/ArtGobblers";

const startBlock = await fetch("http://...");

export default createConfig({
  networks: {
    mainnet: {
      chainId: 1,
      transport: http(process.env.PONDER_RPC_URL_1),
    },
  },
  contracts: {
    ArtGobblers: {
      network: "mainnet",
      abi: ArtGobblersAbi,
      address: "0x60bb1e2aa1c9acafb4d34f71585d7e959f387769",
      startBlock,
    },
  },
});
```

---
title: "Deploy to production"
description: "A guide for deploying Ponder apps to production"
---

import { Steps } from "nextra/components";
import { Callout } from "nextra/components";

# Database reference

<Callout type="info">
  This is a low-level reference designed to assist with advanced workflows. To
  learn how to query indexed data, visit the [query the
  database](/docs/query/direct-sql) guide.
</Callout>

This reference documents the Ponder instance lifecycle, which may be useful for advanced workflows around zero-downtime deployments, crash recovery, and database administration.

## Instance lifecycle

Here is a high-level overview of the Ponder instance lifecycle. Note that "instance" here refers to a Node.js process running `ponder dev` or `ponder start`.

1. Start returning `200` from the `/health` endpoint. Return `503` from the `/ready` endpoint.
2. Build all user code (config, schema, indexing functions), then generate a `build_id` by hashing the build artifacts.
3. Follow the database schema flow chart below to validate and prepare the target database schema.
4. Begin historical indexing, either from scratch or from where the previous instance left off (crash recovery).
5. When historical indexing is complete, start returning `200` from the `/ready` endpoint.
6. On shutdown (e.g. due to a process exit signal), release the lock on the target schema. Do not drop any tables.

### Database schema rules

- No two instances can use the same database schema at the same time. This prevents data corruption.
- Once an instance running `ponder start` uses a schema, no other instance can use that schema ‚Äì even after the instance stops. This is a safety mechanism to prevent data loss in production.
- If the target schema was previously used by `ponder dev`, the new instance will drop the previous tables and start successfully.

Here is the detailed flow chart.

```mermaid
flowchart TD
A[Target schema is currently in use?]

C[Target schema previously used?]
F[Previous instance command?]
E[Previous build ID same as current?]

V(Drop existing tables)
W(Recover from existing tables)
X(Create tables)
Y(Start)
Z1(Error)
Z2(Error)


V --> X
W --> Y
X --> Y

A -- yes --> Z1
A -- no --> C

C -- yes --> F
C -- no --> X

F -- ponder start --> E
F -- ponder dev --> V

E -- no --> Z2
E -- yes --> W

style Y fill:#0a0,color:#fff
style Z1 fill:#f00,color:#fff
style Z2 fill:#f00,color:#fff
```

### Lock / metadata table

The `_ponder_meta` table tracks the state of an instance running in a specific database schema. It stores the `build_id`, indexing checkpoint, and table names of the current instance, and uses a heartbeat locking mechanism to support the lifecycle logic described above.

### Build ID and crash recovery

During the build step, each instance generates a content hash of the entire app (config, schema, and indexing function file contents). This is called the `build_id`.

Note that crash recovery is disabled when running `ponder dev`.

## RPC request cache

Ponder caches RPC request data to improve reindexing performance on hot reloads and redeployments. This includes logs, blocks, transactions, traces, and any RPC requests made with `context.client`.

- The RPC request cache is located in the `ponder_sync` schema.
- The cache is durable, persists across instance restarts, and does not store unfinalized data.
- The cache query patterns are lock-free. It's safe for multiple instances to run in the same Postgres database at the same time (reading and writing to the same `ponder_sync` schema).

---
title: "API Reference: Indexing functions"
description: "Learn about the options available in Ponder indexing functions."
---

import { Callout } from "nextra/components";

# Indexing function API

Indexing functions are user-defined functions that receive blockchain data (a log, block, transaction, trace, or transfer) and insert data into the database. You can register indexing functions within any `.ts` file inside the `src/` directory.

## Registration

To register an indexing function, use the `.on(){:ts}` method of the `ponder` object exported from `"ponder:registry"{:ts}`.

<Callout type="info">
  Values returned by indexing functions are ignored.
</Callout>

```ts filename="src/index.ts" {3}
import { ponder } from "ponder:registry";

ponder.on("ContractName:EventName", async ({ event, context }) => {
  const { db, network, client, contracts } = context;

  // ...
});
```

## Log event

Log events are specified with `"ContractName:EventName"`.

```ts filename="src/index.ts" {3}
import { ponder } from "ponder:registry";

ponder.on("ContractName:EventName", async ({ event, context }) => {
  // ...
});
```

The `event` argument contains the decoded log arguments and the raw log, block, and transaction.

```ts
type LogEvent = {
  name: string;
  args: Args;
  log: Log;
  block: Block;
  transaction: Transaction;
  // Enabled using `includeTransactionReceipts` in contract config
  transactionReceipt?: TransactionReceipt;
};
```

### Log event arguments

The `event.args` object contains decoded `log.topics` and `log.data` decoded using Viem's [decodeEventLog](https://viem.sh/docs/contract/decodeEventLog.html) function.

```ts
/** Sample `args` type for an ERC20 Transfer event. */
type Args = {
  from: `0x${string}`;
  to: `0x${string}`;
  value: bigint;
};
```

## Call trace event

Call trace events are specified using `"ContractName.functionName()"`.

<Callout type="default">
  The [`includeCallTraces` contract
  option](/docs/contracts-and-networks#call-traces) must be enabled to use call
  trace events.
</Callout>

```ts filename="src/index.ts" {3}
import { ponder } from "ponder:registry";

ponder.on("ContractName.functionName()", async ({ event, context }) => {
  // ...
});
```

The `event` argument contains the decoded call trace args and result and the raw trace, block, and transaction.

```ts
type TraceEvent = {
  name: string;
  args: Args;
  result: Result;
  trace: Trace;
  block: Block;
  transaction: Transaction;
  // Enabled using `includeTransactionReceipts` in contract config
  transactionReceipt?: TransactionReceipt;
};
```

### Call trace event arguments

The `event.args` and `event.result` objects contain `trace.input` and `trace.output` decoded using Viem's [decodeFunctionData](https://viem.sh/docs/contract/decodeFunctionData.html) and [decodeFunctionResult](https://viem.sh/docs/contract/decodeFunctionResult.html) functions, respectively.

## Transaction event

Transaction events are specified using `"AccountName:transaction:from"` or `"AccountName:transaction:to"`.

```ts filename="src/index.ts" {3}
import { ponder } from "ponder:registry";

ponder.on("AccountName:transaction:from", async ({ event, context }) => {
  // ...
});
```

The `event` argument contains the raw block, transaction, and transaction receipt.

```ts
type TransactionEvent = {
  block: Block;
  transaction: Transaction;
  transactionReceipt: TransactionReceipt;
};
```

## Transfer event

Native transfer events are specified using `"AccountName:transfer:from"` or `"AccountName:transfer:to"`.

```ts filename="src/index.ts" {3}
import { ponder } from "ponder:registry";

ponder.on("AccountName:transfer:from", async ({ event, context }) => {
  // ...
});
```

The `event` argument contains the transfer and raw block, transaction, and trace.

```ts
type TransferEvent = {
  transfer: {
    from: `0x${string}`;
    to: `0x${string}`;
    value: bigint;
  };
  block: Block;
  transaction: Transaction;
  trace: Trace;
  // Enabled using `includeTransactionReceipts` in account config
  transactionReceipt?: TransactionReceipt;
};
```

## Block event

Block events are specified using `"SourceName:block"`.

```ts filename="src/index.ts" {3}
import { ponder } from "ponder:registry";

ponder.on("SourceName:block", async ({ event, context }) => {
  // ...
});
```

The `event` argument contains the raw block.

```ts
type BlockEvent = {
  block: Block;
};
```

## Event types

```ts filename="Event types"
/** The block containing the transaction that emitted the log being processed. */
type Block = {
  /** Base fee per gas */
  baseFeePerGas: bigint | null;
  /** "Extra data" field of this block */
  extraData: `0x${string}`;
  /** Maximum gas allowed in this block */
  gasLimit: bigint;
  /** Total used gas by all transactions in this block */
  gasUsed: bigint;
  /** Block hash */
  hash: `0x${string}`;
  /** Logs bloom filter */
  logsBloom: `0x${string}`;
  /** Address that received this block‚Äôs mining rewards */
  miner: `0x${string}`;
  /** Block number */
  number: bigint;
  /** Parent block hash */
  parentHash: `0x${string}`;
  /** Root of the this block‚Äôs receipts trie */
  receiptsRoot: `0x${string}`;
  /** Size of this block in bytes */
  size: bigint;
  /** Root of this block‚Äôs final state trie */
  stateRoot: `0x${string}`;
  /** Unix timestamp of when this block was collated */
  timestamp: bigint;
  /** Total difficulty of the chain until this block */
  totalDifficulty: bigint | null;
  /** Root of this block‚Äôs transaction trie */
  transactionsRoot: `0x${string}`;
};

/** The transaction that emitted the log being processed. */
type Transaction = {
  /** Transaction sender */
  from: `0x${string}`;
  /** Gas provided for transaction execution */
  gas: bigint;
  /** Base fee per gas. */
  gasPrice?: bigint | undefined;
  /** Hash of this transaction */
  hash: `0x${string}`;
  /** Contract code or a hashed method call */
  input: `0x${string}`;
  /** Total fee per gas in wei (gasPrice/baseFeePerGas + maxPriorityFeePerGas). */
  maxFeePerGas?: bigint | undefined;
  /** Max priority fee per gas (in wei). */
  maxPriorityFeePerGas?: bigint | undefined;
  /** Unique number identifying this transaction */
  nonce: number;
  /** Transaction recipient or `null` if deploying a contract */
  to: `0x${string}` | null;
  /** Index of this transaction in the block */
  transactionIndex: number;
  /** Value in wei sent with this transaction */
  value: bigint;
};

/** A confirmed Ethereum transaction receipt. */
type TransactionReceipt = {
  /** Address of new contract or `null` if no contract was created */
  contractAddress: Address | null;
  /** Gas used by this and all preceding transactions in this block */
  cumulativeGasUsed: bigint;
  /** Pre-London, it is equal to the transaction's gasPrice. Post-London, it is equal to the actual gas price paid for inclusion. */
  effectiveGasPrice: bigint;
  /** Transaction sender */
  from: Address;
  /** Gas used by this transaction */
  gasUsed: bigint;
  /** List of log objects generated by this transaction */
  logs: Log[];
  /** Logs bloom filter */
  logsBloom: Hex;
  /** `success` if this transaction was successful or `reverted` if it failed */
  status: "success" | "reverted";
  /** Transaction recipient or `null` if deploying a contract */
  to: Address | null;
  /** Transaction type */
  type: TransactionType;
};

/** The log being processed. */
type Log = {
  /** Globally unique identifier for this log (`${blockHash}-${logIndex}`). */
  id: string;
  /** The address from which this log originated */
  address: `0x${string}`;
  /** Contains the non-indexed arguments of the log */
  data: `0x${string}`;
  /** Index of this log within its block */
  logIndex: number;
  /** `true` if this log has been removed in a chain reorganization */
  removed: boolean;
  /** List of order-dependent topics */
  topics: [`0x${string}`, ...`0x${string}`[]] | [];
};

type Trace = {
  /** Globally unique identifier for this trace (`${transactionHash}-${tracePosition}`) */
  id: string;
  /** The type of the call. */
  type:
    | "CALL"
    | "CALLCODE"
    | "DELEGATECALL"
    | "STATICCALL"
    | "CREATE"
    | "CREATE2"
    | "SELFDESTRUCT";
  /** The address of that initiated the call. */
  from: Address;
  /** The address of the contract that was called. */
  to: Address | null;
  /** How much gas was left before the call. */
  gas: bigint;
  /** How much gas was used by the call. */
  gasUsed: bigint;
  /** Calldata input. */
  input: Hex;
  /** Output of the call, if any. */
  output?: Hex;
  /** Error message, if any. */
  error?: string;
  /** Why this call reverted, if it reverted. */
  revertReason?: string;
  /** Value transferred. */
  value: bigint | null;
  /** Index of this trace in the transaction. */
  traceIndex: number;
  /** Number of subcalls. */
  subcalls: number;
};
```

## Context

The `context` argument passed to each indexing function contains database model objects and helper objects based on your config.

At runtime, the indexing engine uses a different `context` object depending on the network the current event was emitted on. The TypeScript types for the `context` object reflect this by creating a union of possible types for `context.network` and `context.contracts`.

{/* prettier-ignore */}
```ts
type Context = {
  db: Database;
  network: { name: string; chainId: number };
  client: ReadOnlyClient;
  contracts: Record<
    string,
    { abi: Abi; address?: `0x${string}`; startBlock?: number; endBlock?: number; }
  >;
};
```

### Database

The `context.db` object is a live database connection. [Read more](/docs/indexing/write-to-the-database) about writing to the database.

```ts filename="src/index.ts" {5-7}
import { ponder } from "ponder:registry";
import { persons, dogs } from "ponder:schema";

ponder.on("Neighborhood:NewNeighbor", async ({ event, context }) => {
  await context.db.insert(persons).values({ name: "bob", age: 30 });
  await context.db.insert(dogs).values({ name: "jake", ownerName: "bob" });
  const jake = await context.db.find(dogs, { name: "jake" });
});
```

### Network

The `context.network` object includes information about the network that the current event is from. The object is strictly typed according to the networks you defined in your config.

```ts filename="src/index.ts"
ponder.on("UniswapV3Factory:Ownership", async ({ event, context }) => {
  context.network;
  //      ^? { name: "mainnet", chainId 1 } | { name: "base", chainId 8453 }

  if (context.network.name === "mainnet") {
    // Do mainnet-specific stuff!
  }
});
```

### Client

<Callout type="info">
  See the [Read contract data](/docs/indexing/read-contract-data) guide for more
  details.
</Callout>

### Contracts

<Callout type="info">
  See the [Read contract data](/docs/indexing/read-contract-data) guide for more
  details.
</Callout>

## `"setup"` event

You can also define a setup function for each contract that runs before indexing begins.

- The indexing function does not receive an `event` argument, only `context`.
- If you read from contracts in a `"setup"` indexing function, the `blockNumber` for the request is set to the contract's `startBlock`.

For example, you might have a singleton `World` record that occasionally gets updated in indexing functions.

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";
import { world } from "ponder:schema";

ponder.on("FunGame:NewPlayer", async ({ context }) => {
  await context.db
    .insert(world)
    .values({ id: 1, playerCount: 0 })
    .onConflictDoUpdate((row) => ({
      playerCount: row.playerCount + 1,
    }));
});
```

Without the `"setup"` event, you need to upsert the record in each indexing function that attempts to use it, which is clunky and bad for performance. Instead, use the `"setup"` event to create the singleton record once at the beginning of indexing.

{/* prettier-ignore */}
```ts filename="src/index.ts"
import { ponder } from "ponder:registry";
import { world } from "ponder:schema";

ponder.on("FunGame:setup", async ({ context }) => {
  await context.db.insert(world).values({
    id: 1,
    playerCount: 0,
  });
});

ponder.on("FunGame:NewPlayer", async ({ context }) => {
  await context.db
    .update(world, { id: 1 })
    .set((row) => ({
      playerCount: row.playerCount + 1,
  }));
});
```

---
title: "API Reference: create-ponder"
description: "Learn about the options available in the create-ponder CLI tool."
---

import { Tabs } from "nextra/components";

# create-ponder

The `create-ponder` CLI tool creates a new Ponder project with `package.json`, `ponder.config.ts`, `ponder.schema.ts`, ABIs, and other project files set up for you. It's the easiest way to get started with Ponder.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm create ponder {...options}
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn create ponder {...options}
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm create ponder@latest {...options}
```
</Tabs.Tab>
</Tabs>

## Options

```sh
Usage:
  $ create-ponder <directory> [options]

Options:
  -t, --template [id]             Use a template
  --etherscan [url]               Use the Etherscan template with the specified contract URL
  --etherscan-api-key [key]       Etherscan API key for Etherscan template
  --subgraph [id]                 Use the subgraph template with the specified subgraph ID
  --subgraph-provider [provider]  Specify the subgraph provider
  --npm                           Use npm as your package manager
  --pnpm                          Use pnpm as your package manager
  --yarn                          Use yarn as your package manager
  --skip-git                      Skip initializing a git repository
  --skip-install                  Skip installing packages
  -h, --help                      Display this message
  -v, --version                   Display version number
```

## Templates

Templates help get you started faster by copying contract addresses, ABIs, and deployment blocks from an existing source.

### Etherscan contract link

The `--etherscan [url]` option creates a project using the address, ABI, and deployment block number of a contract on a block explorer. **Enter the full URL, not just the contract address.**

#### Chain support

The template uses the `viem/chains` list of block explorer URLs to determine the chain ID and fetch the contract ABI. Please reference the [`viem/chains` definitions](https://github.com/wevm/viem/tree/main/src/chains/definitions) to see if your block explorer is supported. If you'd like to use an unsupported block explorer, please open a PR there to add it.

![Etherscan contract link screenshot](/etherscan-link.png)

### Subgraph ID

The `--subgraph [id]` option creates a project from an existing subgraph by fetching the addresses, ABIs, and start blocks for each event source defined in `subgraph.yaml`.

To find the subgraph ID, go to the subgraph's page on the [hosted service](https://thegraph.com/hosted-service/subgraph/protofire/makerdao-governance) or [Graph Explorer](https://thegraph.com/explorer/).

![Subgraph ID screenshot](/subgraph-id.png)

### Example projects

The `-t, --template [id]` option creates a new project from one of the [example projects](https://github.com/ponder-sh/ponder/tree/main/examples).
For example, this command creates a project using the `feature-factory` example project.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm create ponder --template feature-factory
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn create ponder --template feature-factory
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm create ponder@latest --template feature-factory
```
</Tabs.Tab>
</Tabs>

Here are the available projects:

| Name                   | Template ID              | Link                                                                                      |
| :--------------------- | :----------------------- | :---------------------------------------------------------------------------------------- |
| Factory contract       | feature-factory          | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-factory)          |
| Custom event filter    | feature-filter           | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-filter)           |
| Multiple chains        | feature-multichain       | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-multichain)       |
| Proxy contract         | feature-proxy            | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-proxy)            |
| Contract calls         | feature-read-contract    | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/feature-read-contract)    |
| Friendtech project     | project-friendtech       | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/project-friendtech)       |
| Uniswap V3 flash loans | project-uniswap-v3-flash | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/project-uniswap-v3-flash) |
| Basic ERC20 token      | reference-erc20          | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/reference-erc20)          |
| Basic ERC721 token     | reference-erc721         | [GitHub](https://github.com/ponder-sh/ponder/tree/main/examples/reference-erc721)         |

---
title: "API Reference: Ponder CLI"
description: "Learn about the options available in the Ponder CLI."
---

import { Callout } from "nextra/components";

# CLI commands

The CLI (provided by the `ponder` package) is the entrypoint for your project.

```bash
Usage: ponder <command> [OPTIONS]

Options:
  --schema <SCHEMA>      Database schema
  --root <PATH>          Path to the project root directory (default: working directory)
  --config <PATH>        Path to the project config file (default: "ponder.config.ts")
  -v, --debug            Enable debug logs, e.g. realtime blocks, internal events
  -vv, --trace           Enable trace logs, e.g. db queries, indexing checkpoints
  --log-level <LEVEL>    Minimum log level ("error", "warn", "info", "debug", or "trace") (default: "info")
  --log-format <FORMAT>  The log format ("pretty" or "json") (default: "pretty")
  -V, --version          Show the version number
  -h, --help             Show this help message

Commands:
  dev [options]          Start the development server with hot reloading
  start [options]        Start the production server
  serve [options]        Start the production HTTP server without the indexer
  db list                List all deployments
  codegen                Generate the schema.graphql file, then exit
```

## dev

Start the app in development mode.

- The app automatically restarts when changes are detected in any project file.
- An auto-updating terminal UI displays useful information.

```bash
Usage: ponder dev [options]

Start the development server with hot reloading

Options:
  -p, --port <PORT>          Port for the web server (default: 42069)
  -H, --hostname <HOSTNAME>  Hostname for the web server (default: "0.0.0.0" or "::")
  -h, --help                 display help for command
```

## start

Start the app in production mode.

- Project files are built once on startup, and file changes are ignored.
- The terminal UI is disabled.

```bash
Usage: ponder start [options]

Start the production server

Options:
  -p, --port <PORT>          Port for the web server (default: 42069)
  -H, --hostname <HOSTNAME>  Hostname for the web server (default: "0.0.0.0" or "::")
  -h, --help                 display help for command
```

## serve

Start the app in server-only mode. This option can be used to horizontally scale the GraphQL API in production.

- Only works with Postgres.
- Project files are built once on startup, and file changes are ignored.
- The sync and indexing engines is disabled.
- The GraphQL API server runs as normal, serving data from the connected database.

```bash
Usage: ponder serve [options]

Start the production HTTP server without the indexer

Options:
  -p, --port <PORT>          Port for the web server (default: 42069)
  -H, --hostname <HOSTNAME>  Hostname for the web server (default: "0.0.0.0" or "::")
  -h, --help                 display help for command
```

## db list

List all deployments.

```bash
Usage: ponder db list

List all deployments

‚îÇ Schema        ‚îÇ Active   ‚îÇ Last active    ‚îÇ Table count ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ indexer_prod  ‚îÇ      yes ‚îÇ            --- ‚îÇ          10 ‚îÇ
‚îÇ test          ‚îÇ       no ‚îÇ    26m 58s ago ‚îÇ          10 ‚îÇ
‚îÇ demo          ‚îÇ       no ‚îÇ      1 day ago ‚îÇ           5 ‚îÇ
```

## codegen

<Callout type="info">
  During development (when using `ponder dev`), codegen runs automatically run
  when changes are detected in `ponder.schema.ts`.
</Callout>

Generate the `schema.graphql` file.

```bash
Usage: ponder codegen [options]

Generate the schema.graphql file, then exit

Options:
  -h, --help  display help for command
```

---
title: "API Reference: ponder.schema.ts"
description: "Learn about the options available in ponder.schema.ts, Ponder's schema definition file."
---

import { Callout } from "nextra/components";

# Schema API

The `ponder.schema.ts` file defines your database tables and their relationships. Tables defined in this file are used to store indexed blockchain data and are automatically exposed via the GraphQL API.

## File requirements

The `ponder.schema.ts` must use **named exports** for tables, enums, and relations, and these objects must be created using the corresponding functions exported by `ponder`.

```ts filename="ponder.schema.ts" {1,3}
import { onchainTable } from "ponder";

export const pets = onchainTable("pets", (t) => ({
  name: t.text().primaryKey(),
  age: t.integer().notNull(),
}));
```

## `onchainTable`

The `onchainTable` function accepts three positional arguments.

| Argument       | Type                                           | Description                                                                               |
| :------------- | :--------------------------------------------- | :---------------------------------------------------------------------------------------- |
| `name`         | `string`                                       | The SQL table name. Use `snake_case`.                                                     |
| `columns`      | `(t: TableBuilder) => Record<string, Column>`  | A function that returns column definitions.                                               |
| `constraints?` | `(table: Table) => Record<string, Constraint>` | Optional function that returns table constraints like composite primary keys and indexes. |

{/* prettier-ignore */}
```ts filename="ponder.schema.ts"
import { onchainTable } from "ponder";

export const transferEvents = onchainTable(
  "transfer_event", // SQL table name
  (t) => ({ // Column definitions
    id: t.text().primaryKey(),
    from: t.hex().notNull(),
    to: t.hex().notNull(),
    value: t.bigint().notNull(),
  }),
  (table) => ({  // Constraints & indexes
    fromIdx: index().on(table.from),
  })
);
```

### Column types

The schema definition API supports most PostgreSQL data types. Here's a quick reference for the most commonly used data types. For a complete list, see the [Drizzle documentation](https://orm.drizzle.team/docs/column-types/pg).

| Name             | Description                                  | TypeScript type          | SQL data type         |
| :--------------- | :------------------------------------------- | :----------------------- | :-------------------- |
| `text{:ts}`      | UTF‚Äê8 character sequence                     | `string`                 | `TEXT{:sql}`          |
| `integer{:ts}`   | Signed 4‚Äêbyte integer                        | `number`                 | `INTEGER{:sql}`       |
| `real{:ts}`      | Signed 4-byte floating‚Äêpoint value           | `number`                 | `REAL{:sql}`          |
| `boolean{:ts}`   | `true` or `false`                            | `boolean`                | `BOOLEAN{:sql}`       |
| `timestamp{:ts}` | Date and time value (no time zone)           | `Date`                   | `TIMESTAMP{:sql}`     |
| `json{:ts}`      | JSON object                                  | `any` or [custom](#json) | `JSON{:sql}`          |
| `bigint{:ts}`    | Large integer (holds `uint256` and `int256`) | `bigint`                 | `NUMERIC(78,0){:sql}` |
| `hex{:ts}`       | UTF‚Äê8 character sequence with `0x` prefix    | `0x${string}`            | `TEXT{:sql}`          |

### Column modifiers

Column modifiers can be chained after column type definitions.

| Modifier                      | Description                                    |
| :---------------------------- | :--------------------------------------------- |
| `.primaryKey(){:ts}`          | Marks column as the table's primary key        |
| `.notNull(){:ts}`             | Marks column as NOT NULL                       |
| `.array(){:ts}`               | Marks column as an array type                  |
| `.default(value){:ts}`        | Sets a default value for column                |
| `.$default(() => value){:ts}` | Sets a dynamic default via function            |
| `.$type<T>(){:ts}`            | Annotates column with a custom TypeScript type |

### Constraints

#### Primary key

Every table must have exactly one primary key defined using either the `.primaryKey()` column modifier or the `primaryKey()` function in the table constraints argument.

```ts filename="ponder.schema.ts" {1, 5, 16}
import { onchainTable, primaryKey } from "ponder";

// Single column primary key
export const tokens = onchainTable("tokens", (t) => ({
  id: t.bigint().primaryKey(),
}));

// Composite primary key
export const poolStates = onchainTable(
  "pool_states",
  (t) => ({
    poolId: t.bigint().notNull(),
    address: t.hex().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.poolId, table.address] }),
  })
);
```

### Indexes

Create indexes using the `index()` function in the constraints & indexes argument. The indexing engine creates indexes after historical indexing completes, just before
the app becomes healthy.

```ts filename="ponder.schema.ts" {1,10}
import { onchainTable, index } from "ponder";

export const persons = onchainTable(
  "persons",
  (t) => ({
    id: t.text().primaryKey(),
    name: t.text(),
  }),
  (table) => ({
    nameIdx: index().on(table.name),
  })
);
```

## `onchainEnum`

The `onchainEnum` function accepts two positional arguments. It returns a function that can be used as a column type.

| Argument | Type       | Description                                                       |
| :------- | :--------- | :---------------------------------------------------------------- |
| `name`   | `string`   | The SQL enum name. Use `snake_case`.                              |
| `values` | `string[]` | An array of strings representing the allowed values for the enum. |

```ts filename="ponder.schema.ts" {3}
import { onchainEnum, onchainTable } from "ponder";

export const color = onchainEnum("color", ["ORANGE", "BLACK"]);

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  color: color().notNull(),
}));
```

Like any other column types, you can use modifiers like `.notNull()`, `.default()`, and `.array()` with enum columns.

```ts filename="ponder.schema.ts" {5}
// ...

export const dogs = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  color: color().array().default([]),
}));
```

## `relations`

Use the `relations` function to define relationships between tables.

```ts filename="ponder.schema.ts" {1,7}
import { onchainTable, relations } from "ponder";

export const users = onchainTable("users", (t) => ({
  id: t.text().primaryKey(),
}));

export const usersRelations = relations(users, ({ one }) => ({
  profile: one(profiles, {
    fields: [users.id],
    references: [profiles.userId],
  }),
}));
```

### Relationship types

| Type             | Method      | Description                                    |
| :--------------- | :---------- | :--------------------------------------------- |
| **One-to-one**   | `one()`     | References single related record               |
| **One-to-many**  | `many()`    | References array of related records            |
| **Many-to-many** | Combination | Uses join table with two one-to-many relations |

Read more in the [relationships guide](/docs/schema#relationships) and the Drizzle [relations documentation](https://orm.drizzle.team/docs/relations).

---
title: "Call traces"
description: "Learn how to index call traces in a Ponder app"
---

import { Callout, Steps } from "nextra/components";

# Call traces

Call traces are similar to logs, but they represent a _function call_ instead of an event log.

<Callout type="warning">
  Call traces are slower, more expensive, and less widely supported than logs.
  For new chains, you might struggle to find an RPC provider that supports the
  `debug_traceBlockByNumber` and `debug_traceBlockByHash` methods.
</Callout>

## Register an indexing function

Call trace indexing is **disabled** by default. To enable it for a contract, set the `includeCallTraces{:ts}` option to `true{:ts}`.

After enabling this option, each function in the contract ABI will become available as an indexing function event name using the `"ContractName.functionName()"{:ts}` scheme.

<div className="code-columns">

```ts filename="ponder.config.ts" {11}
import { createConfig } from "ponder";
import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  contracts: {
    Blitmap: {
      abi: BlitmapAbi,
      network: "mainnet",
      address: "0x8d04a8c79cEB0889Bdd12acdF3Fa9D207eD3Ff63",
      startBlock: 12439123,
      includeCallTraces: true,
    },
  },
  // ...
});
```

```ts filename="src/index.ts" {15}
import { ponder } from "ponder:registry";

ponder.on("Blitmap.mintOriginal()", async ({ event }) => {
  event.args;
  //    ^? [tokenData: Hex, name: string]
  event.trace.gasUsed;
  //          ^? bigint
});
```

</div>

## What is a call trace?

Let's define call traces from three different perspectives:

- **Ponder**: A call trace is similar to a log, but it represents a function call instead of an event log. You can register an indexing function that will run whenever a specific function on one of your contracts gets called.
- **Solidity**: A call trace records a function call. For example, whenever someone calls the `transfer(address to, uint256 amount){:solidity}` function of an ERC20 token contract, it produces a call trace.
- **EVM**: A call trace records the execution of the [`CALL`, `STATICCALL`, `DELEGATECALL`, or `CALLCODE`](https://www.evm.codes/#f1) opcode within a transaction.

### Top-level vs. internal calls

A call trace can be a **top-level call** or an **internal call**. A top-level call is from an externally-owned account, and an internal call is from another contract.

To determine if a specific call trace is a top-level call, use `event.trace.traceAddress.length === 0{:ts}`. Top-level calls also always have `event.trace.to === event.transaction.to{:ts}`, but this can also be true for internal calls.

```ts filename="src/index.ts" {2}
ponder.on("ERC20.transfer()", async ({ event }) => {
  const isTopLevelCall = event.trace.traceAddress.length === 0;
  // ...
});
```

### `eth_call` and `view` functions

The `eth_call` RPC method **does not** produce a call trace. These calls do not occur during the execution of a transaction, so they are not recorded as call traces.

However, calls made to `view` or `pure` functions **do** produce call traces if they are made during the execution of a transaction. These call traces are rarely useful for indexing, but they do happen.

---
title: "mergeAbis"
description: "API reference for the mergeAbis utility function."
---

import { Callout } from "nextra/components";

# mergeAbis

Combines many ABIs into one. Removes duplicate items if necessary.

## Usage

```ts filename="index.ts" {1,4}
import { mergeAbis } from "@ponder/utils";
import { erc20Abi, erc4626Abi } from "viem";

const tokenAbi = mergeAbis([erc20Abi, erc4626Abi]);
```

## Usage in Ponder

Use `mergeAbis` to preserve type safety when combining multiple ABIs for a single contract. This is especially useful for proxy contracts that have had several different implementation ABIs.

For convenience, `ponder` re-exports `mergeAbis` from `@ponder/utils`.

```ts filename="ponder.config.ts" {1,14}
import { createConfig, mergeAbis } from "ponder";
import { http } from "viem";

import { ERC1967ProxyAbi } from "./abis/ERC1967Proxy";
import { NameRegistryAbi } from "./abis/NameRegistry";
import { NameRegistry2Abi } from "./abis/NameRegistry2";

export default createConfig({
  networks: {
    goerli: { chainId: 5, transport: http(process.env.PONDER_RPC_URL_5) },
  },
  contracts: {
    FarcasterNameRegistry: {
      abi: mergeAbis([ERC1967ProxyAbi, NameRegistryAbi, NameRegistry2Abi]),
      network: "goerli",
      address: "0xe3Be01D99bAa8dB9905b33a3cA391238234B79D1",
      startBlock: 7648795,
    },
  },
});
```

## Parameters

### ABIs

- Type: `Abi[]{:ts}` (required)

A list of ABIs to merge.

## Returns

- Type: `Abi{:ts}`

A new ABI including all items from the input list, with duplicates removed.

---
title: "Utility types"
description: "API reference for Ponder utility types."
---

import { Callout } from "nextra/components";

# Utility types

To enable code reuse and maintain type safety for advanced use cases, Ponder offers utility types that are aware of your `ponder.config.ts` and `ponder.schema.ts` files.

## Indexing function types

The `"ponder:registry"{:ts}` module exports utility types that are useful for creating reusable helper functions in your indexing files.

### EventNames

A union of all event names that are available from the contracts defined in `ponder.config.ts`.

```ts filename="src/helpers.ts" {1}
import { ponder, type EventNames } from "ponder:registry";

function helper(eventName: EventNames) {
  eventName;
  // ^? "Weth:Deposit" | "Weth:Withdraw" | "Weth:Approval | "Weth:Transfer"
}
```

### Event

A generic type that optionally accepts an event name and returns the `event` object type for that event.

```ts filename="src/helpers.ts" {1}
import { ponder, type Event } from "ponder:registry";

function helper(event: Event<"Weth:Deposit">) {
  event;
  // ^? {
  //      args: { dst: `0x${string}`; wad: bigint };
  //      block: Block;
  //      event: "Deposit";
  //      transaction: Transaction;
  //      log: Log;
  //    }
}
```

If no event name is provided, `Event` is the union of all event types. This can be useful if all you need is the `block`, `transaction`, and `log` types which are the same for all events.

```ts filename="src/helpers.ts" {1}
import { ponder, type Event } from "ponder:registry";

function helper(event: Event) {
  event;
  // ^? { args: { dst: `0x${string}`; wad: bigint }; block: Block; event: "Deposit"; transaction: Transaction; log: Log; }
  //    | { args: { src: `0x${string}`; wad: bigint }; block: Block; event: "Withdraw"; transaction: Transaction; log: Log; }
  //    ...
}
```

### Context

A generic type that optionally accepts an event name and returns the `context` object type.

```ts filename="src/helpers.ts" {1}
import { ponder, type Context } from "ponder:registry";

function helper(context: Context<"Weth:Deposit">) {
  event;
  // ^? {
  //      network: { name: "mainnet"; chainId: 1; };
  //      client: ReadonlyClient;
  //      db: { Account: DatabaseModel<{ id: `0x${string}`; balance: bigint; }> };
  //      contracts: { weth9: { abi: ...; address: "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2" } };
  //    }
}
```

If no event name is provided, `Context` returns the union of all context types. This can be useful if all you need is the `db` or `contracts` types which are the same for all events.

### IndexingFunctionArgs

A generic type that optionally accepts an event name and returns the indexing function argument type.

```ts filename="src/helpers.ts" {1}
import { ponder, type IndexingFunctionArgs } from "ponder:registry";

function helper(args: IndexingFunctionArgs<"Weth:Deposit">) {
  args;
  // ^? {
  //      event: { ... };
  //      context: { ... };
  //    }
}
```

Like `Event` and `Context`, `IndexingFunctionArgs` returns the union of all indexing function argument types if no event name is provided.

### Schema

Use the [Drizzle type helpers](https://orm.drizzle.team/docs/goodies#type-api) to create custom types for database records.

```ts filename="src/helpers.ts" {3}
import { accounts } from "ponder:schema";

function helper(account: typeof accounts.$inferSelect) {
  account;
  // ^? {
  //      id: bigint;
  //      balance: bigint;
  //      nickname: string;
  //      createdAt: number;
  //    }
}
```

## Config types

The `ponder` package exports a utility type for each option passed to `createConfig(){:ts}`.

### ContractConfig

The type of a contract in `createConfig(){:ts}`.

```ts filename="ponder.config.ts" {1}
import { createConfig, type ContractConfig } from "ponder";
import { Erc20Abi } from "./abis/Erc20Abi.ts";

const Erc20 = {
  network: "mainnet"
  abi: Erc20Abi,
  address: "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2",
} as const satisfies ContractConfig;

export default createConfig({
  networks: ...,
  contracts: {
    Erc20,
  },
});
```

### NetworkConfig

The type of a network in `createConfig(){:ts}`.

```ts filename="ponder.config.ts" {1}
import { createConfig, type NetworkConfig } from "ponder";
import { http } from "viem";

const mainnet = {
  chainId: 1,
  transport: http(process.env.PONDER_RPC_URL_1),
} as const satisfies NetworkConfig;

export default createConfig({
  networks: {
    mainnet,
  }
  contracts: ...,
});
```

### BlockConfig

The type of a block source in `createConfig(){:ts}`.

```ts filename="ponder.config.ts" {1}
import { createconfig, type blockconfig } from "ponder";

const ChainlinkPriceOracle = {
  network: "mainnet",
  startBlock: 19_750_000,
  interval: 5,
} as const satisfies BlockConfig;

export default createConfig({
  networks: ...,
  blocks: {
    ChainlinkPriceOracle,
  },
});
```

### DatabaseConfig

The type of a database in `createConfig(){:ts}`.

```ts filename="ponder.config.ts" {1,6}
import { createConfig, type DatabaseConfig } from "ponder";

const database = {
  kind: "postgres",
  connectionString: process.env.DATABASE_URL,
} as const satisfies DatabaseConfig;

export default createConfig({
  networks: ...,
  contracts: ...,
  database,
});
```

---
title: "replaceBigInts"
description: "API reference for the replaceBigInts utility function."
---

import { Callout } from "nextra/components";

# replaceBigInts

Replaces all instances of [`BigInt`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt) in an object with a new value, specified by a replacer function.

## Usage

This example simply converts `BigInt` values to a string.

```ts filename="index.ts" {5}
import { replaceBigInts } from "@ponder/utils";

const obj = { a: 100n, b: [-12n, 3_000_000_000n] };

const result = replaceBigInts(obj, (v) => String(v));
//    ?^ { a: '100', b: [ '-12', '3000000000' ] }
```

## Usage in Ponder

Here are a few common scenarios where you might want to replace `BigInt` values in a Ponder app.

### `json` columns

The [`json` column type](/docs/schema#json-type) does not support `BigInt` values. Use `replaceBigInts` to prepare objects containing `BigInt` values for insertion.

```ts filename="src/index.ts" {2,9}
import { ponder } from "ponder:registry";
import { userOperations } from "ponder:schema";
import { replaceBigInts } from "@ponder/utils";
import { toHex } from "viem";

ponder.on("EntryPoint:UserOp", async ({ event, context }) => {
  await context.db.insert(userOperations).values({
    id: event.log.id,
    receipt: replaceBigInts(event.transactionReceipt, toHex),
  });
});
```

To maintain type safety for column values, use the `ReplaceBigInts{:ts}` helper type in the column `$type` annotation.

```ts filename="ponder.schema.ts" {1,7}
import { onchainTable } from "ponder";
import type { ReplaceBigInts } from "@ponder/utils";
import type { TransactionReceipt, Hex } from "viem";

export const userOperations = onchainTable("user_operations", (t) => ({
  id: t.text().primaryKey(),
  receipt: t.json<ReplaceBigInts<TransactionReceipt, Hex>>(),
}));
```

### HTTP responses

The GraphQL API automatically serializes `BigInt` values to strings before returning them in HTTP responses. In API functions, you need to handle this serialization process manually.

```ts filename="src/api/index.ts" {2,16}
import { ponder } from "ponder:registry";
import { accounts } from "ponder:schema";
import { replaceBigInts } from "@ponder/utils";
import { numberToHex } from "viem";

ponder.get("/whale-balances", async (c) => {
  const rows = await c.db
    .select({
      address: accounts.address,
      ethBalance: accounts.ethBalance,
      dogeBalance: accounts.dogeBalance,
    })
    .from(accounts)
    .where(eq(accounts.address, address));

  const result = replaceBigInts(rows, (v) => numberToHex(v));

  return c.json(result);
});
```

## Replacer functions

Here are three common ways to replace `BigInt` values.

| Encoding            | Replacer type                  | Replacer function                                                 |
| :------------------ | :----------------------------- | :---------------------------------------------------------------- |
| **Hex**             | `` `0x${string}` {:ts}``       | [`numberToHex`](https://viem.sh/docs/utilities/toHex#numbertohex) |
| **String**          | `string`                       | `String`                                                          |
| **Lossless string** | `` `#bigint.${string}` {:ts}`` | `` (x) => `#bigint.${String(x)}` {:ts}``                          |

See the [Wagmi FAQ](https://wagmi.sh/react/guides/faq#bigint-serialization) for more information on `BigInt` serialization.

## Parameters

### value

- Type: `any{:ts}`

The scalar, array, or object containing `BigInt{:ts}` values to be replaced.

### replacer

- Type: `(value: bigint) => JSONSerializable{:ts}`

A custom replacer function that will be called for each `BigInt` value.

## Returns

### value

The scalar, array, or object with all `BigInt{:ts}` values replaced.

---
title: "Viem Transports"
description: "API reference for load balancing and rate limiting Viem Transports."
---

import { Callout } from "nextra/components";

# Transports

The `@ponder/utils` package exports two new [Viem transports](https://viem.sh/docs/clients/intro#transports), `loadBalance` and `rateLimit`. These transports are useful for managing the RPC request workloads that Ponder apps commonly encounter.

## Load balance

The `loadBalance` Transport distributes requests across a list of inner Transports in a simple round-robin scheme.

### Usage

```ts {7-12}
import { loadBalance } from "@ponder/utils";
import { createPublicClient, fallback, http, webSocket } from "viem";
import { mainnet } from "viem/chains";

const client = createPublicClient({
  chain: mainnet,
  transport: loadBalance([
    http("https://cloudflare-eth.com"),
    http("https://eth-mainnet.public.blastapi.io"),
    webSocket("wss://ethereum-rpc.publicnode.com"),
    rateLimit(http("https://rpc.ankr.com/eth"), { requestsPerSecond: 5 }),
  ]),
});
```

### Usage in Ponder

For convenience, `ponder` re-exports `loadBalance` from `@ponder/utils`.

```ts filename="ponder.config.ts" {8-13}
import { createConfig, loadBalance } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: {
    mainnet: {
      chainId: 1,
      transport: loadBalance([
        http("https://cloudflare-eth.com"),
        http("https://eth-mainnet.public.blastapi.io"),
        webSocket("wss://ethereum-rpc.publicnode.com"),
        rateLimit(http("https://rpc.ankr.com/eth"), { requestsPerSecond: 5 }),
      ]),
    },
  },
  contracts: {
    // ...
  },
});
```

### Parameters

#### Transports

Type: `Transport[]` (required)

A list of Transports to load balance requests across.

## Rate limit

The `rateLimit` Transport limits the number of requests per second submitted to an inner Transport using a first-in-first-out queue.

### Usage

```ts {7-9}
import { rateLimit } from "@ponder/utils";
import { createPublicClient, fallback, http } from "viem";
import { mainnet } from "viem/chains";

const client = createPublicClient({
  chain: mainnet,
  transport: rateLimit(http("https://eth-mainnet.g.alchemy.com/v2/..."), {
    requestsPerSecond: 25,
  }),
});
```

### Usage in Ponder

For convenience, `ponder` re-exports `rateLimit` from `@ponder/utils`.

```ts filename="ponder.config.ts" {8-10}
import { createConfig, rateLimit } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: {
    mainnet: {
      chainId: 1,
      transport: rateLimit(http(process.env.PONDER_RPC_URL_1), {
        requestsPerSecond: 25,
      }),
    },
  },
  contracts: {
    // ...
  },
});
```

### Parameters

#### Transport

Type: `Transport` (required)

An inner transport to rate limit.

#### requestsPerSecond

Type: `number{:ts}` (required)

#### browser

Type: `boolean{:ts}` (default: `true{:ts}`)

If `false{:ts}`, the internal queue will use the Node.js-specific `process.nextTick(){:ts}` API to schedule requests. This leads to more predictable behavior in Node.js, but is not available in the browser.

---
title: "Database"
description: "A guide to set up the Ponder database."
---

import { Tabs, Callout } from "nextra/components";

# Set up the database

Ponder supports two database options.

- **PostgreSQL**: A traditional Postgres database server. Required for production, can be used for local development.
- **PGlite**: An embedded Postgres database that runs in the same process as your Ponder app. Only suitable for local development.

## Choose a database

By default, Ponder uses PGlite with data stored in the `.ponder` directory. To use Postgres, set the `DATABASE_URL` environment variable to a Postgres connection string, or use explicit configuration in `ponder.config.ts`.

```ts filename="ponder.config.ts"
import { createConfig } from "ponder";

export default createConfig({
  database: {
    kind: "postgres",
    connectionString: "postgresql://user:password@localhost:5432/dbname",
  },
  // ... more config
});
```

Visit the `ponder.config.ts` [API reference](/docs/api-reference/config#database) for more details.

## Database schema

When you start a Ponder app, you must specify which **database schema** it should use. This is where the app will create the tables defined in `ponder.schema.ts`.

Use the `DATABASE_SCHEMA` environment variable or the `--schema` CLI option to configure it.

<div className="code-columns">

```bash filename=".env.local"
DATABASE_SCHEMA=my_schema
```

```bash filename="shell"
ponder start --schema my_schema
```

</div>

### Guidelines

Here are the key guidelines to keep in mind when selecting a database schema.

- No two Ponder instances/deployments can use the same database schema at the same time.
- Tables created by `ponder start` are treated as valuable and will never be dropped automatically.
- The default schema for `ponder dev` is `public`. When using `ponder start`, you must explicitly set the database schema; there is no default.
- Use `ponder dev` for local development; `ponder start` is intended for production.

{/* - Use `ponder db drop {schema name}` to reuse a schema previously used by `ponder start`. */}

[Read more](/docs/api-reference/database) about the instance lifecycle and database schema rules.

---
title: "Create a new project"
description: "Get started with Ponder in just a few minutes using a template."
---

import { Steps, Tabs, Callout } from "nextra/components";

# Quickstart

<Steps>

### Create a new Ponder project

<Callout type="info">
  If the contract you're indexing has already been deployed, use the Etherscan
  link [template](/docs/api-reference/create-ponder#etherscan-contract-link).
</Callout>

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm create ponder
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn create ponder
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm create ponder@latest
```
</Tabs.Tab>
</Tabs>

You will be asked for a project name, and if you are using a [template](/docs/api-reference/create-ponder#templates) (recommended). Then, it will create a project directory, install dependencies, and initialize a git repository.

### Start the development server

Just like Next.js and Vite, Ponder has a development server that automatically reloads when you save changes in any project file. It also prints `console.log` statements and errors encountered while running your code.

First, `cd` into your project directory, then start the server.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```
pnpm dev
```
</Tabs.Tab>
  <Tabs.Tab>
```
yarn dev
```
</Tabs.Tab>
  <Tabs.Tab>
```
npm run dev
```
</Tabs.Tab>
</Tabs>

### Add an RPC URL

Ponder fetches data using the standard Ethereum RPC API. To get started, you'll need an RPC URL from a provider like Alchemy or Infura.

Open `.env.local` and paste in RPC URLs for any networks that your project uses.

Each RPC URL environment variable is named `PONDER_RPC_URL` postfixed with the chain ID (e.g. `PONDER_RPC_URL_8453` for Base Mainnet):

{/* prettier-ignore */}
```js filename=".env.local"
PONDER_RPC_URL_1 = "https://eth-mainnet.g.alchemy.com/v2/..."
```

### Design your schema

The `ponder.schema.ts` file contains the database schema, and defines the shape data that the GraphQL API serves.

```ts filename="ponder.schema.ts"
import { onchainTable } from "ponder";

export const blitmapTokens = onchainTable("blitmap_tokens", (t) => ({
  id: t.integer().primaryKey(),
  owner: t.hex(),
}));
```

Read more about [designing your schema](/docs/schema).

### Write indexing functions

Files in the `src/` directory contain **indexing functions**, which are TypeScript functions that process a contract event. The purpose of these functions is to write indexed data to the database.

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";
import { blitmapTokens } from "ponder:schema";

ponder.on("Blitmap:Transfer", async ({ event, context }) => {
  await context.db.insert(blitmapTokens).values({
    id: event.args.tokenId,
    owner: event.args.to,
  });
});
```

Read more on how to [write to the database](/docs/indexing/write-to-the-database) and [read contract data](/docs/indexing/read-contract-data).

### Query the GraphQL API

As you write your indexing functions and start inserting data, open the GraphiQL interface at `http://localhost:42069/graphql` to explore your GraphQL API locally. Any changes you make to your `ponder.schema.ts` file will be reflected here.

<div className="code-columns">

{/* prettier-ignore */}
```graphql filename="Query"
query {
  blitmapTokens {
    id
    owner
  }
}
```

{/* prettier-ignore */}
```json filename="Result"
{
  "blitmapTokens": [
    { "id": 1452, "owner": "0xaf3d5..." },
    { "id": 7164, "owner": "0x9cb3b..." },
  ]
}
```

</div>

</Steps>

---
title: "System requirements"
description: "A guide for installing Ponder on any platform."
---

import { Tabs, Callout } from "nextra/components";

# System requirements

The [`create-ponder` CLI](/docs/getting-started/new-project) is the best way to get started. If `create-ponder` runs without error, your system meets the requirements.

## Requirements

- MacOS, Linux, or Windows
- [Node.js](https://nodejs.org/en) >=18 (support for Bun is [in progress](https://github.com/ponder-sh/ponder/issues/442))
- [pnpm](https://pnpm.io/installation) (recommended), [yarn](https://yarnpkg.com/getting-started/install), or npm
- [PostgreSQL](https://www.postgresql.org/download/) version 14, 15, 16 or 17.

### Windows

Ponder supports Windows via PowerShell, command prompt (cmd.exe), or Windows Subsystem for Linux (WSL). If you encounter a Windows-specific problem, please [open an issue](https://github.com/ponder-sh/ponder/issues).

## TypeScript

Ponder uses advanced TypeScript features to offer end-to-end type safety without code generation. We **strongly** recommend taking the time to set up a working TypeScript development environment ‚Äì it will pay dividends in the long run.

### Requirements

- TypeScript `>=5.0.4`, viem `>=2`, and hono `>=4.5
- ABIs must be asserted `as const` following [ABIType guidelines](https://abitype.dev/guide/getting-started#usage)
- The `ponder-env.d.ts` file must be present and up to date

### `ponder-env.d.ts`

This "magical" file is what makes Ponder's zero-codegen type system possible. The file contains a module declaration for `"ponder:registry"{:ts}` that exports types derived from `ponder.config.ts` and `ponder.schema.ts`.

After upgrading to a new version of `ponder`, the dev server might make changes to `ponder-env.d.ts`. When this happens, please accept and commit the changes.

### VSCode

By default, VSCode's TypeScript language features use an internal version of TypeScript. Sometimes, this version does not meet Ponder's requirement of `>=5.0.4`.

To change VSCode's TypeScript version, run `TypeScript: Select TypeScript version..."` from the command palette and select `Use Workspace Version` or [update VSCode's version](https://stackoverflow.com/questions/39668731/what-typescript-version-is-visual-studio-code-using-how-to-update-it).

---
title: "Migrate a Graph Protocol subgraph"
description: "Learn how to rapidly migrate a Graph Protocol subgraph to Ponder."
---

import { Callout, Steps, Tabs } from "nextra/components";

# Migrate a Graph Protocol subgraph

<Steps>

### Create a Ponder project

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm create ponder
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn create ponder
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm create ponder@latest
```
</Tabs.Tab>
</Tabs>

First, enter a project name. Then select the **Subgraph ID** template option and paste in your subgraph's deployment ID:

![Subgraph ID screenshot](/subgraph-id.png)

<div className="caption">
  [MakerDAO's
  subgraph](https://thegraph.com/hosted-service/subgraph/protofire/makerdao-governance)
  on the Graph Protocol's hosted service.
</div>

The newly generated Ponder app will copy the subgraph's `schema.graphql` as well as the addresses, ABIs, and start blocks for each event source defined in `subgraph.yaml`. Then, it will create a project directory, install dependencies, and initialize a git repository.

### Start the development server

Just like Next.js and Vite, Ponder has a development server that automatically reloads when you save changes in any project file. It also prints `console.log` statements and errors encountered while running your code.

First, `cd` into your project directory, then start the server.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm dev
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn dev
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm run dev
```
</Tabs.Tab>
</Tabs>

### Add an RPC URL

Ponder fetches data using the standard Ethereum RPC API. To get started, you'll need an RPC URL from a provider like Alchemy or Infura.

Open `.env.local` and paste in RPC URLs for any networks that your project uses.

Each RPC URL environment variable is named `PONDER_RPC_URL` postfixed with the chain ID (e.g. `PONDER_RPC_URL_8453` for Base Mainnet):

{/* prettier-ignore */}
```js filename=".env.local"
PONDER_RPC_URL_1 = "https://eth-mainnet.g.alchemy.com/v2/..."
```

### Write indexing functions

Open any file in the `src/` directory. Ponder indexing functions are very similar to subgraph mapping functions, with some key differences. You will need to refactor your code, but because the local dev server has hot reloading, you'll get instant feedback on your changes.

See [tips for migrating mapping functions](#migration-tips) for more details.

### Query the GraphQL API

As you migrate your indexing functions and start inserting data, open the GraphiQL interface at `http://localhost:42069/graphql` to explore your GraphQL API locally. Any changes you make to your `ponder.schema.ts` file will be reflected here.

</Steps>

## Migration tips

### Functions run in Node.js, not WebAssembly

You can import NPM packages, debug with `console.log`, and use normal JavaScript types like `string` and `number`.

### Database & contracts are injected, not imported

In a Graph Protocol subgraph mapping file, entity models and contract factories are imported:

```ts filename="mapping.ts (Graph Protocol)"
import { Token, Wallet } from "../generated/schema";
import { MyNftContract } from "../generated/MyNftContract/MyNftContract";

export function handleTransfer(event) {
  // Get an entity object
  const token = Token.load(event.params.id);

  // Bind and call a contract
  const tokenUri = MyNftContract.bind("0x137...01a2").tokenURI(token.id);

  // ...
}
```

With Ponder, these objects are injected as properties of `context`.

```ts filename="src/MyNftContract.ts"
import { ponder } from "ponder:registry";
import { tokens } from "ponder:schema";

ponder.on("MyNftContract:Transfer", async ({ event, context }) => {
  // Get a database record
  const token = await context.db.find(tokens, { id: event.args.id });

  // Call a contract read function
  const tokenUri = await context.client.readContract({
    abi: context.contracts.MyNftContract.abi,
    address: context.contracts.MyNftContract.address,
    functionName: "tokenURI",
    args: [event.args.tokenId],
  });

  // ...
});
```

Read more on how to [write to the database](/docs/indexing/write-to-the-database) and [read contract data](/docs/indexing/read-contract-data).

---
title: "Time-series data"
description: "Techniques for working with time-series data in a Ponder app."
---

import { Callout, FileTree, Steps } from "nextra/components";

# Time-series data

This guide describes techniques for working with time-series data in your app.

## Candlestick charts (bucketing)

To power a [candlestick](https://en.wikipedia.org/wiki/Candlestick_chart) or open-high-low-close chart, create a table that stores OHLC data for a specific time interval.

```ts filename="ponder.schema.ts"
import { onchainTable } from "ponder";

export const hourBuckets = onchainTable("hour_buckets", (t) => ({
  id: t.integer().primaryKey(),
  open: t.real().notNull(),
  close: t.real().notNull(),
  low: t.real().notNull(),
  high: t.real().notNull(),
  average: t.real().notNull(),
  count: t.integer().notNull(),
}));
```

Then, in your indexing function, create or update the bucket record that the current event falls into.

```ts filename="src/index.ts"
import { ponder, type Schema } from "ponder:registry";

const secondsInHour = 60 * 60;

ponder.on("Token:Swap", async ({ event, context }) => {
  const { timestamp } = event.block;
  const { price } = event.args;

  const hourId = Math.floor(timestamp / secondsInHour) * secondsInHour;

  await context.db
    .insert(hourBuckets)
    .values({
      id: hourId,
      open: price,
      close: price,
      low: price,
      high: price,
      average: price,
      count: 1,
    })
    .onConflictDoUpdate((row) => ({
      close: price,
      low: Math.min(row.low, price),
      high: Math.max(row.high, price),
      average: (row.average * row.count + price) / (row.count + 1),
      count: row.count + 1,
    }));
});
```

Here are GraphQL and SQL queries that return the last 48 hours of OHLC data. These queries could be used to power a chart on your frontend.

<div class="code-columns">

```graphql filename="GraphQL query"
{
  hourBuckets(orderBy: { id: "desc" }, limit: 48) {
    items {
      id
      open
      close
      low
      high
      average
      count
    }
  }
}
```

```sql filename="SQL query"
SELECT *
  FROM "HourBucket"
  ORDER BY id DESC
  LIMIT 48;
```

</div>

## Include `block.timestamp`

The simplest way to add a time dimension to your data is to include the block number or block timestamp (or both!) as a column.

<div class="code-columns">

```ts filename="ponder.schema.ts"
import { onchainTable } from "ponder";

export const swapEvents = onchainTable("swap_events", (t) => ({
  id: t.text().primaryKey(),
  from: t.hex().notNull(),
  to: t.hex().notNull(),
  amount: t.bigint().notNull(),
  timestamp: t.bigint().notNull(),
}));
```

```ts filename="src/index.ts" {10}
import { ponder } from "ponder:registry";
import { swapEvents } from "ponder:schema";

ponder.on("Token:Swap", async ({ event, context }) => {
  await context.db.insert(swapEvents).values({
    id: event.log.id,
    from: event.args.from,
    to: event.args.to,
    amount: event.args.amount,
    timestamp: event.block.timestamp,
  });
});
```

</div>

Now, you can use the `timestamp` column to filter and sort data over different time intervals.

```graphql filename="GraphQL query"
{
  swapEvents(
    orderBy: { timestamp: "desc" }
    where: { timestamp_gt: 1712500000, timestamp_lt: 1713000000 }
  ) {
    items {
      id
      from
      to
      amount
      timestamp
    }
  }
}
```

---
title: "Deploy to production"
description: "A guide for deploying Ponder apps to production"
---

import { Steps, Tabs, Callout } from "nextra/components";

# Deploy

You can deploy your Ponder app to any cloud environment that supports Node.js.

- [Railway](#railway)
- [Self-hosting](#self-hosting)

## Railway

[Railway](https://railway.app)'s general-purpose cloud platform is a great starting point for most Ponder apps.

<Steps>

### Log in to Railway

Connect your GitHub account, and make sure that your Ponder app has been pushed to remote.

### Create a Ponder app service

From the Railway console:

1. Click **New Project** ‚Üí **Deploy from GitHub repo** and select your repo from the list
2. Click **Add variables**, then add RPC URLs (e.g. `PONDER_RPC_URL_1`) and other environment variables
3. Create a public domain. In **Settings** ‚Üí **Networking**, click **Generate Domain**
4. Update the start command. In **Settings** ‚Üí **Deploy**, set the **Custom Start Command** to include the `--schema` option. This is required to enable zero-downtime deployments. [Read more](/docs/getting-started/database#database-schema).

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```text filename="Start command"
pnpm start --schema $RAILWAY_DEPLOYMENT_ID
```
</Tabs.Tab>
  <Tabs.Tab>
```text filename="Start command"
yarn start --schema $RAILWAY_DEPLOYMENT_ID
```
</Tabs.Tab>
  <Tabs.Tab>
```text filename="Start command"
npm run start -- --schema $RAILWAY_DEPLOYMENT_ID
```
</Tabs.Tab>
</Tabs>

5. Set the healthcheck path and timeout. In **Settings** ‚Üí **Deploy**, set the **Healthcheck Path** to `/ready` and the **Healthcheck Timeout** to `86400` seconds (1 day)

<Callout type="info">
  _Monorepo users:_ Use the **Root Directory** and/or **Start Command** options
  to run `ponder start` at the Ponder project root, e.g. set the root directory
  to `packages/ponder` or set the start command to `cd packages/ponder && pnpm
  start`.
</Callout>

### Create a Postgres database

From the new project dashboard:

1. Click **Create** ‚Üí **Database** ‚Üí **Add PostgreSQL**
2. Open the **Variables** tab for the Ponder app service, click **New Variable** ‚Üí **Add Reference** ‚Üí select `DATABASE_URL` and click **Add**

</Steps>

After a moment, the service running `ponder start` should redeploy successfully. Check the **Build Logs** and **Deploy Logs** tabs to debug any issues.

## Self hosting

In general, hosting a Ponder app is similar to hosting a normal Node.js web server. This section describes the key Ponder-specific quirks to consider when self-hosting.

### Database connection

<Callout type="info">
  Your app will run into performance issues if the roundtrip database latency
  exceeds ~20 milliseconds. This is common when using a database in different
  private network or cloud region.
</Callout>

In production, Ponder works best with a Postgres database in the same private network. Set the `DATABASE_URL` environment variable to the connection string of your Postgres database, or manually override the `database.connectionString` option in `ponder.config.ts`.

```ts filename="ponder.config.ts" {6}
import { createConfig } from "ponder";

export default createConfig({
  database: {
    kind: "postgres",
    connectionString: "postgres://user:password@mycloud.internal:5432/database",
  },
  // ... more config
});
```

### Database schema

Each deployment must use a different database schema. Use the `DATABASE_SCHEMA` environment variable or the `--schema` CLI argument passed to `ponder start` to specify which database schema each deployment should use. [Read more](/docs/api-reference/database#database-schema-rules) about database schema selection rules.

The best choice depends on your deployment strategy ‚Äì here are a few common options.

- Kubernetes pod name
- Railway deployment ID
- Git branch name or commit hash

### Health checks & probes

Use the `/health` and `/ready` endpoints to configure health checks or [probes](https://kubernetes.io/docs/concepts/configuration/liveness-readiness-startup-probes/).

- **`/health`**: Returns an HTTP `200` response immediately after the process starts.
- **`/ready`**: Returns an HTTP `200` response once indexing progress has reached realtime across all chains. During the historical backfill, the endpoint returns an HTTP `503` response.

### Crash recovery

If a Ponder app running `ponder start` crashes and restarts using the same database schema, it will attempt to resume indexing where it left off. [Read more](/docs/api-reference/database#build-id-and-crash-recovery) about the instance lifecycle and crash recovery mechanism.

## Advanced

### Scale the HTTP server

If a `ponder start` instance receives a large volume of HTTP traffic (e.g. GraphQL requests), the HTTP server will contend with the indexing engine for CPU and memory resources. This can lead to degraded indexing performance and might ultimately crash the instance.

To solve this problem, you can use `ponder serve` to run additional instances of the HTTP server without the indexing engine. Here are a few things to keep in mind.

- The `ponder serve` instance should use the same [database schema](#database-schema) as the `ponder start` instance that you'd like to scale.
- If one `ponder serve` instance is not enough, you can safely run multiple replicas behind a proxy using an architecture like this.

```mermaid
graph LR
  A[Clients]
  B[Proxy]
  C["HTTP (ponder serve)"]
  D["HTTP (ponder serve)"]
  E["HTTP (ponder serve)"]
  F["Database"]
  G["Indexer (ponder start)"]
  A --> B
  B --> C
  B --> D
  B --> E
  C --> F
  D --> F
  E --> F
  F <--> G
```

### Database maintenance

The `ponder db` CLI entrypoint offers a set of commands useful for observing and maintaining your database. [Read more](/docs/api-reference/ponder-cli#db).

---
title: "Design your schema"
description: "A guide for designing your schema in a Ponder app."
---

import { Callout } from "nextra/components";

# Design your schema

Ponder's schema definition API is built on [Drizzle](https://orm.drizzle.team/), a modern TypeScript ORM.

To create a table, use the `onchainTable` function exported by `ponder` and include column definitions.

```ts filename="ponder.schema.ts" {1,3}
import { onchainTable } from "ponder";

export const pets = onchainTable("pets", (t) => ({
  name: t.text().primaryKey(),
  age: t.integer().notNull(),
}));
```

<Callout type="info">
  Remember to export table objects using `export const`. Ponder will ignore
  tables that are not exported.
</Callout>

## Columns

### Column types

The schema definition API supports most PostgreSQL data types. Here's a quick reference for the most commonly used data types. For a complete list, see the [Drizzle documentation](https://orm.drizzle.team/docs/column-types/pg).

| name             | description                        | TypeScript type          | SQL data type     |
| :--------------- | :--------------------------------- | :----------------------- | :---------------- |
| `text{:ts}`      | UTF‚Äê8 character sequence           | `string`                 | `TEXT{:sql}`      |
| `integer{:ts}`   | Signed 4‚Äêbyte integer              | `number`                 | `INTEGER{:sql}`   |
| `real{:ts}`      | Signed 4-byte floating‚Äêpoint value | `number`                 | `REAL{:sql}`      |
| `boolean{:ts}`   | `true` or `false`                  | `boolean`                | `BOOLEAN{:sql}`   |
| `timestamp{:ts}` | Date and time value (no time zone) | `Date`                   | `TIMESTAMP{:sql}` |
| `json{:ts}`      | JSON object                        | `any` or [custom](#json) | `JSON{:sql}`      |

Ponder also includes a few extra column types built specifically for EVM indexing.

| name          | description                                  | TypeScript type | SQL data type         |
| :------------ | :------------------------------------------- | :-------------- | :-------------------- |
| `bigint{:ts}` | Large integer (holds `uint256` and `int256`) | `bigint`        | `NUMERIC(78,0){:sql}` |
| `hex{:ts}`    | UTF‚Äê8 character sequence with `0x` prefix    | `0x${string}`   | `TEXT{:sql}`          |

<h4 className="text-lg font-semibold mt-10">`bigint`</h4>

The `bigint` column type can hold any EVM `uint256` or `int256` value.

```ts filename="ponder.schema.ts" {5}
import { onchainTable } from "ponder";

export const accounts = onchainTable("accounts", (t) => ({
  address: t.hex().primaryKey(),
  balance: t.bigint().notNull(),
}));
```

<Callout type="info">
  Ponder's `bigint` type takes precedence over the Drizzle
  [`bigint`](https://orm.drizzle.team/docs/column-types/pg#bigint) type, which
  is an 8-byte integer (too small for EVM `uint256` or `int256` values). To
  create an 8-byte integer column, use the `int8` alias.
</Callout>

<h4 className="text-lg font-semibold mt-10">`hex`</h4>

The `hex` column type is useful for EVM `address`, `bytes`, or any other hex-encoded value.

```ts filename="ponder.schema.ts" {4}
import { onchainTable } from "ponder";

export const accounts = onchainTable("accounts", (t) => ({
  address: t.hex().primaryKey(),
  balance: t.bigint().notNull(),
}));
```

### Enums

To define an enum, use the `onchainEnum` function exported by `ponder`. Then, use the value returned by `onchainEnum` as a column type. Under the hood, `onchainEnum` uses a PostgreSQL [enumerated type](https://www.postgresql.org/docs/current/datatype-enum.html).

```ts filename="ponder.schema.ts" {3,7}
import { onchainEnum, onchainTable } from "ponder";

export const color = onchainEnum("color", ["ORANGE", "BLACK"]);

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  color: color("color"),
}));
```

### Arrays

To define an array column, use the `.array(){:ts}` modifier. Arrays are a good fit for small one-dimensional collections, not [relationships](#relationships) between records.

```ts filename="ponder.schema.ts" {5}
import { onchainTable } from "ponder";

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  vaccinations: t.text().array(), // ["rabies", "distemper", "parvo"]
}));
```

### Not null

To mark a column as not null, use the `.notNull(){:ts}` modifier. If you attempt to insert a row that does not include a value for a `NOT NULL{:sql}` column, the database will throw an error.

```ts filename="ponder.schema.ts" {5}
import { onchainTable } from "ponder";

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  age: t.integer().notNull(),
}));
```

### Default value

To set a default value for a column, use the `.default(){:ts}` modifier and pass a string, number, boolean, or `null`.

```ts filename="ponder.schema.ts" {5}
import { onchainTable } from "ponder";

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  livesRemaining: t.integer().default(9),
}));
```

Alternatively, use the `.$default(){:ts}` modifier to specify a JavaScript function that returns the default value. With this approach, the database driver calls the function before inserting a row into this table that does not include a value for this column.

```ts filename="ponder.schema.ts" {6}
import { onchainTable } from "ponder";
import { generateId } from "../utils";

export const cats = onchainTable("cats", (t) => ({
  name: t.text().primaryKey(),
  age: t.integer().$default(() => generateId()),
}));
```

## Relationships

Ponder uses Drizzle Relations to define relationships between tables. Here are some examples of how to define one-to-one, one-to-many, and many-to-many relationships. For more information, see the [Drizzle Relations documentation](https://orm.drizzle.team/docs/relations).

<Callout type="info">
  Relations are useful to connect tables in the Query API (`findMany` and
  `findFirst`) and the GraphQL API. However, relations **do not** create foreign
  key constraints and won't stop you from inserting rows that violate
  referential integrity.
</Callout>

### One-to-one

Use the `relations` function exported by `ponder` to define the relationships for a table.

To define a one-to-one relationship, use the `one()` operator and specify which columns relate the two tables. In this example, each user has a profile and each profile belongs to one user.

```ts filename="ponder.schema.ts" {1,7-9}
import { onchainTable, relations } from "ponder";

export const users = onchainTable("users", (t) => ({
  id: t.text().primaryKey(),
}));

export const usersRelations = relations(users, ({ one }) => ({
  profile: one(profiles, { fields: [users.id], references: [profiles.userId] }),
}));

export const profiles = onchainTable("profiles", (t) => ({
  id: t.text().primaryKey(),
  userId: t.text().notNull(),
  age: t.integer().notNull(),
}));
```

Now that you've defined the relationship, the `profile` field will become available in the Query API (`findMany` and `findFirst`) using the `with` option.

```ts filename="src/index.ts" {8,11}
import { users, profiles } from "ponder:schema";

await db.insert(users).values({ id: "hunter42" });
await db.insert(profiles).values({ userId: "hunter42", age: 29 });

const user = await db.sql.query.users.findFirst({
  where: eq(users.id, "hunter42"),
  with: { profile: true },
});

console.log(user.profile.age);
//          ^? { id: string; profile: { id: string; userId: string; age: number } }
```

### One-to-many

To define a one-to-many relationship, use the `one()` and `many()` operators to define both sides of the relationship. In this example, each dog has one owner and each person can own many dogs.

```ts filename="ponder.schema.ts" {7-9,16-18}
import { onchainTable, relations } from "ponder";

export const persons = onchainTable("persons", (t) => ({
  name: t.text().primaryKey(),
}));

export const personsRelations = relations(persons, ({ many }) => ({
  dogs: many(dogs),
}));

export const dogs = onchainTable("dogs", (t) => ({
  petId: t.text().primaryKey(),
  ownerName: t.text().notNull(),
}));

export const dogsRelations = relations(dogs, ({ one }) => ({
  owner: one(persons, { fields: [dogs.ownerName], references: [persons.name] }),
}));
```

Now, any row inserted into the `dogs` table with `ownerName: "Bob"` will become available in Bob's `dogs` field.

```ts filename="src/index.ts" {11,15}
import { persons, dogs } from "ponder:schema";

await db.insert(persons).values({ name: "Bob" });
await db.insert(dogs).values([
  { petId: "Chip", ownerName: "Bob" },
  { petId: "Spike", ownerName: "Bob" },
]);

const bob = await db.sql.query.persons.findFirst({
  where: eq(persons.id, "Bob"),
  with: { dogs: true },
});

console.log(bob.dogs);
//          ^? { name: string; dogs: { petId: string; age: number }[] }
```

<Callout type="info">
  Note that in a one-to-many relationship, you cannot directly set the value of
  the `many` field. Instead, you must insert or update the related rows
  individually.
</Callout>

### Many-to-many

To define a many-to-many relationship, create a "join table" that relates the two tables you want to connect using two one-to-many relationships.

{/* prettier-ignore */}
```ts filename="ponder.schema.ts" {7-9,16-18,30-33}
import { onchainTable, relations } from "ponder";

export const users = onchainTable("users", (t) => ({
  id: t.text().primaryKey(),
}));

export const usersRelations = relations(users, ({ many }) => ({
  userTeams: many(userTeams),
}));

export const teams = onchainTable("teams", (t) => ({
  id: t.text().primaryKey(),
  mascot: t.text().notNull(),
}));

export const teamsRelations = relations(teams, ({ many }) => ({
  userTeams: many(userTeams),
}));

export const userTeams = onchainTable(
  "user_teams",
  (t) => ({
    userId: t.text().notNull(),
    teamId: t.text().notNull(),
  }),
  // A composite primary key is often a good choice for a join table.
  (table) => ({ pk: primaryKey({ columns: [table.userId, table.teamId] }) })
);

export const userTeamsRelations = relations(userTeams, ({ one }) => ({
  user: one(users, { fields: [userTeams.userId], references: [users.id] }),
  team: one(teams, { fields: [userTeams.teamId], references: [teams.id] }),
}));
```

Now, any row inserted into the `userTeams` table will create a relationship between the `user` and `team` records. You can query for the relationship by nesting the `with` option in the Query API.

{/* prettier-ignore */}
```ts filename="src/index.ts" {19}
import { users, teams, userTeams } from "ponder:schema";

await db.insert(users).values([
  { id: "ron" }, { id: "harry" }, { id: "hermione" }
]);
await db.insert(teams).values([
  { id: "muggle", mascot: "dudley" },
  { id: "wizard", mascot: "hagrid" },
]);
await db.insert(userTeams).values([
  { userId: "ron", teamId: "wizard" },
  { userId: "harry", teamId: "wizard" },
  { userId: "hermione", teamId: "muggle" },
  { userId: "hermione", teamId: "wizard" },
]);

const hermione = await db.sql.query.users.findFirst({
  where: eq(users.id, "hermione"),
  with: { userTeams: { with: { team: true } } },
});

console.log(hermione.userTeams);
//          ^? {
//            id: string;
//            userTeams: {
//              userId: string;
//              teamId: string;
//              team: {
//                id: string;
//                mascot: string
//              }
//            }[]
//          }
```

### Relationships in GraphQL

Every relationship you define in `ponder.schema.ts` will automatically become available in the GraphQL API, with `one` relations creating singular fields and `many` relations creating plural/connection fields.

The [one-to-many example](#one-to-many) above corresponds to the following GraphQL query and result.

<div className="code-columns">

{/* prettier-ignore */}
```graphql filename="Query"
query {
  person(id: "Bob") {
    id
    dogs {
      id
    }
  }
}
```

{/* prettier-ignore */}
```json filename="Result"
{
  "person": {
    "id": "Bob",
    "dogs": [
      { "id": "Chip" },
      { "id": "Spike" }
    ]
  }
}
```

</div>

## Tables

### Primary key

Every table **must** have a primary key. To create a single-column primary key, use the `.primaryKey(){:ts}` modifier.

```ts filename="ponder.schema.ts" {4}
import { onchainTable } from "ponder";

export const tokens = onchainTable("tokens", (t) => ({
  id: t.bigint().primaryKey(),
}));
```

To create a composite primary key, use the `primaryKey()` function exported by `ponder`. All components of the primary key constraint must be unique and not null.

```ts filename="ponder.schema.ts" {11}
import { onchainTable, primaryKey } from "ponder";

export const poolStates = onchainTable(
  "pool_states",
  (t) => ({
    poolId: t.bigint().notNull(),
    address: t.hex().notNull(),
    balance: t.bigint().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.poolId, table.address] }),
  })
);
```

### Indexes

To create a database index, use the `index(){:ts}` function exported by `ponder`. The following example creates an index on the `persons.name` column to speed up search queries, and an index on the `dogs.ownerId` column to speed up the `persons.dogs` relational query.

```ts filename="ponder.schema.ts" {10,25}
import { onchainTable, relations, index } from "ponder";

export const persons = onchainTable(
  "persons",
  (t) => ({
    id: t.text().primaryKey(),
    name: t.text(),
  }),
  (table) => ({
    nameIdx: index().on(table.name),
  })
);

export const personsRelations = relations(persons, ({ many }) => ({
  dogs: many(dogs),
}));

export const dogs = onchainTable(
  "dogs",
  (t) => ({
    id: t.text().primaryKey(),
    ownerId: t.text().notNull(),
  }),
  (table) => ({
    ownerIdx: index().on(table.ownerId),
  })
);

export const dogsRelations = relations(dogs, ({ one }) => ({
  owner: one(persons, { fields: [dogs.ownerId], references: [persons.id] }),
}));
```

The `index(){:ts}` function supports specifying multiple columns, ordering, and custom index types like GIN and GIST. Read more in the [Drizzle](https://orm.drizzle.team/docs/indexes-constraints#indexes) and [PostgreSQL](https://www.postgresql.org/docs/current/indexes.html) documention.

<Callout type="info">
  To improve performance, database indexes are created _after_ historical
  indexing is complete, just before the app becomes healthy.
</Callout>

## Best practices

### Composite primary keys

If a table has two or more columns that together form a unique identifier for a row, use a composite primary key.

Consider an `allowances` table storing ERC20 token allowances. Each row in this table represents the allowance granted by one owner to one spender.

```ts filename="ponder.schema.ts" {10}
import { onchainTable, primaryKey } from "ponder";

export const allowances = onchainTable(
  "allowances",
  (t) => ({
    owner: t.hex(),
    spender: t.hex(),
    amount: t.bigint(),
  }),
  (table) => ({ pk: primaryKey({ columns: [table.owner, table.spender] }) })
);
```

### Timestamps

Use the `bigint` column type to store block timestamps using their EVM-native Unix timestamp representation. This maintains consistency with Viem's approach, and avoids error-prone timezone manipulation code.

```ts filename="ponder.schema.ts" {5}
import { onchainTable } from "ponder";

export const events = onchainTable("events", (t) => ({
  id: t.text().primaryKey(),
  timestamp: t.bigint(), // Unix timestamp in seconds
}));
```

If you strongly prefer working with JavaScript `Date` objects, you can also use the `timestamp` column type, but we recommend doing this conversion in the view layer.

```ts filename="ponder.schema.ts" {5}
import { onchainTable } from "ponder";

export const events = onchainTable("events", (t) => ({
  id: t.text().primaryKey(),
  timestamp: t.timestamp(), // JavaScript Date object
}));
```

### Custom types

Use the `.$type()` modifier to customize the TypeScript type for a column. Note that the `.$type()` modifier does not validate data at runtime or in the database, it only enforces a TypeScript type.

{/* prettier-ignore */}
```ts filename="ponder.schema.ts" {5}
import { onchainTable } from "ponder";

export const tokens = onchainTable("tokens", (t) => ({
  id: t.bigint().primaryKey(),
  metadata: t.json().$type<{ name: string; symbol: string; decimals: number }>(),
}));
```

### `camelCase` vs `snake_case`

Use `camelCase` for TypeScript names and `snake_case` for SQL names. This guideline applies to all database objects and properties, including tables, columns, relations, and indexes.

```ts filename="ponder.schema.ts"
import { onchainTable } from "ponder";

export const registrationEvents = onchainTable(
  "registration_events", // Use snake_case for the SQL table name
  (t) => ({
    createdAt: t.bigint(), // Drizzle automatically converts this to `created_at`
    invitedBy: t.text("invited_by"), // Avoid manual case conversion for columns
    // ...
  })
);
```

## Examples

### ERC20

Here's a schema for a simple ERC20 app.

```ts filename="ponder.schema.ts"
import { index, onchainTable, primaryKey } from "ponder";

export const account = onchainTable("account", (t) => ({
  address: t.hex().primaryKey(),
  balance: t.bigint().notNull(),
  isOwner: t.boolean().notNull(),
}));

export const allowance = onchainTable(
  "allowance",
  (t) => ({
    owner: t.hex(),
    spender: t.hex(),
    amount: t.bigint().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.owner, table.spender] }),
  })
);

export const transferEvent = onchainTable(
  "transfer_event",
  (t) => ({
    id: t.text().primaryKey(),
    amount: t.bigint().notNull(),
    timestamp: t.integer().notNull(),
    from: t.hex().notNull(),
    to: t.hex().notNull(),
  }),
  (table) => ({
    fromIdx: index().on(table.from),
  })
);

export const approvalEvent = onchainTable("approval_event", (t) => ({
  id: t.text().primaryKey(),
  amount: t.bigint().notNull(),
  timestamp: t.integer().notNull(),
  owner: t.hex().notNull(),
  spender: t.hex().notNull(),
}));
```

---
title: "Migration Guide"
description: "A guide for migrating to new versions of Ponder."
---

import { FileTree, Steps, Tabs, Callout } from "nextra/components";

# Migration guide

## 0.8

<Callout type="warning">
  This release includes an irreversible migration to the `ponder_sync` schema (RPC request cache). Once you run a `0.8` app against a database, you can no longer run `<=0.7` apps against the same database.
</Callout>

### Database management

Ponder now requires the database schema to be explicitly specified with an environment variable or CLI flag. **`onchainSchema()` is removed.**

<div className="code-columns">

```bash filename=".env.local"
DATABASE_SCHEMA=my_schema
```

```bash filename="shell"
ponder start --schema my_schema
```

</div>

<Callout type="info">
  Each deployment/instance of a Ponder app must have it's own schema, with some
  exceptions for `ponder dev` and crash recovery. [Read
  more](/docs/getting-started/database#database-schema).
</Callout>

#### Railway

Railway users should [update the start command](/docs/production/deploy#create-a-ponder-app-service) to include a database schema.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```text filename="Start command"
pnpm start --schema $RAILWAY_DEPLOYMENT_ID
```
</Tabs.Tab>
  <Tabs.Tab>
```text filename="Start command"
yarn start --schema $RAILWAY_DEPLOYMENT_ID
```
</Tabs.Tab>
  <Tabs.Tab>
```text filename="Start command"
npm run start -- --schema $RAILWAY_DEPLOYMENT_ID
```
</Tabs.Tab>
</Tabs>

#### `ponder db list`

A new command was added for more visibility into which database schemas are being used.

```bash filename="shell"
$ ponder db list

‚îÇ Schema        ‚îÇ Active   ‚îÇ Last active    ‚îÇ Table count ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ indexer_prod  ‚îÇ      yes ‚îÇ            --- ‚îÇ          10 ‚îÇ
‚îÇ test          ‚îÇ       no ‚îÇ    26m 58s ago ‚îÇ          10 ‚îÇ
‚îÇ demo          ‚îÇ       no ‚îÇ      1 day ago ‚îÇ           5 ‚îÇ
```

### New features

#### Account indexing

A new event source `accounts` is available. Accounts can be used to index transactions and native transfers to and from an address. [Read more](/docs/accounts).

#### `ponder:schema` alias

The `ponder:schema` virtual module was added. It is an alias for `ponder.schema.ts`.

```diff filename="src/index.ts"
- import { accounts } from "../ponder.schema";
+ import { accounts } from "ponder:schema";
```

It also contains a default export of all the exported table objects from `ponder.schema.ts`.

{/* prettier-ignore */}
```ts filename="src/index.ts" {1,3}
import schema from "ponder:schema";
 
const row = await db.insert(schema.accounts).values({
  address: "0x7Df1", balance: 0n
});
```

### Breaking changes

#### `@ponder/core` ‚Üí `ponder`

New versions will be published to `ponder` and not `@ponder/core`.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm remove @ponder/core
pnpm add ponder
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn remove @ponder/core
yarn add ponder
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm remove @ponder/core
npm add ponder
```
</Tabs.Tab>
</Tabs>

#### `@/generated` ‚Üí `ponder:registry`

The virtual module `@/generated` was replaced with `ponder:registry`.

```diff filename="src/index.ts"
- import { ponder } from "@/generated";
+ import { ponder } from "ponder:registry";
```

#### `factory()` function

The `factory()` function replaces the `factory` property in the contract config. The result should be passed to the `address` property.

<div className="code-columns">

```ts filename="ponder.config.ts (<=0.7)" {6-10}
import { createConfig } from "@ponder/core";

export default createConfig({
  contracts: {
    uniswap: {
      factory: {
        address: "0x1F98431c8aD98523631AE4a59f267346ea31F984",
        event: getAbiItem({ abi: UniswapV3FactoryAbi, name: "PoolCreated" }),
        parameter: "pool",
      },
    },
  },
});
```

{/* prettier-ignore */}
```ts filename="ponder.config.ts (0.8)" {6-10}
import { createConfig, factory } from "ponder";

export default createConfig({
  contracts: {
    uniswap: {
      address: factory({
        address: "0x1F98431c8aD98523631AE4a59f267346ea31F984",
        event: getAbiItem({ abi: UniswapV3FactoryAbi, name: "PoolCreated" }),
        parameter: "pool",
      }),
    },
  },
});
```

</div>

#### `ponder-env.d.ts`

A new `ponder-env.d.ts` is required. The new file uses [triple slash directives](https://www.typescriptlang.org/docs/handbook/triple-slash-directives.html#-reference-types-) for (hopefully) less frequent updates.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm codegen
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn codegen
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm run codegen
```
</Tabs.Tab>
</Tabs>

#### Removed `transactionReceipt.logs`

The `transactionReceipt.logs` property was removed from the `event` object.

#### Removed redundant properties from `event`

The following properties were removed from the `event` object.

```diff
- event.log.blockNumber;
- event.log.blockHash;
- event.log.transactionHash;
- event.log.transactionIndex;
- event.transaction.blockNumber;
- event.transaction.blockHash;
- event.transactionReceipt.transactionHash;
- event.transactionReceipt.transactionIndex;
```

All of the data is still available on other properties of the `event` object, such as `event.transaction.hash` or `event.block.number`.

## 0.7

The `0.7` release includes several breaking changes.

### Install & run codegen

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm add @ponder/core@0.7
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn add @ponder/core@0.7
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm add @ponder/core@0.7
```
</Tabs.Tab>
</Tabs>

To ensure strong type safety during the migration, regenerate `ponder-env.d.ts`.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm codegen
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn codegen
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm run codegen
```
</Tabs.Tab>
</Tabs>

### Migrate `ponder.schema.ts`

Here's a table defined with the new schema definition API, which uses [Drizzle](https://orm.drizzle.team/docs/overview) under the hood.

```ts filename="ponder.schema.ts (after)"
import { onchainTable } from "@ponder/core";

export const accounts = onchainTable("account", (t) => ({
  address: t.hex().primaryKey(),
  daiBalance: t.bigint().notNull(),
  isAdmin: t.boolean().notNull(),
  graffiti: t.text(),
}));
```

Key changes:

1. Declare tables with the `onchainTable` function exported from `@ponder/core`
2. Export all table objects from `ponder.schema.ts`
3. Use `.primaryKey()` to mark the primary key column
4. Columns are nullable by default, use `.notNull()` to add the constraint

The new `onchainTable` function adds several new capabilities.

- Custom primary key column name (other than `id`)
- Composite primary keys
- Default column values

Here's a more advanced example with indexes and a composite primary key.

```ts filename="ponder.schema.ts"
import { onchainTable, index, primaryKey } from "@ponder/core";

export const transferEvents = onchainTable(
  "transfer_event",
  (t) => ({
    id: t.text().primaryKey(),
    amount: t.bigint().notNull(),
    timestamp: t.integer().notNull(),
    from: t.hex().notNull(),
    to: t.hex().notNull(),
  }),
  (table) => ({
    fromIdx: index().on(table.from),
  })
);

export const allowance = onchainTable(
  "allowance",
  (t) => ({
    owner: t.hex().notNull(),
    spender: t.hex().notNull(),
    amount: t.bigint().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.owner, table.spender] }),
  })
);

export const approvalEvent = onchainTable("approval_event", (t) => ({
  id: t.text().primaryKey(),
  amount: t.bigint().notNull(),
  timestamp: t.integer().notNull(),
  owner: t.hex().notNull(),
  spender: t.hex().notNull(),
}));
```

### Migrate indexing functions

This release updates the indexing function database API to offer a unified SQL experience based on Drizzle.

Here's an indexing function defined with the new API, which uses the table objects exported from `ponder.schema.ts`.

{/* prettier-ignore */}
```ts filename="src/index.ts"
import { ponder } from "@/generated";
import { account } from "../ponder.schema";

ponder.on("ERC20:Transfer", async ({ event, context }) => {
  await context.db
    .insert(account)
    .values({ 
      address: event.args.from, 
      balance: 0n, 
      isOwner: false,
    })
    .onConflictDoUpdate((row) => ({
      balance: row.balance - event.args.amount,
    }));
});
```

Key changes:

1. Transition from ORM pattern `db.Account.create({ ... }){:ts}` to query builder pattern `db.insert(accounts, { ... }){:ts}`
2. Import table objects from `ponder.schema.ts`
3. Replace `findMany` with `db.sql.select(...)` or `db.sql.query(...)`

Here is a simple migration example to familiarize yourself with the API.

<div className="code-columns">

```ts filename="src/index.ts (<=0.6)"
// Create a single allowance
await context.db.Allowance.create({
  id: event.log.id,
  data: {
    owner: event.args.owner,
    spender: event.args.spender,
    amount: event.args.amount,
  },
});
```

{/* prettier-ignore */}
```ts filename="src/index.ts (0.7)"
import { allowance } from "../ponder.schema";

// Create a single allowance
await context.db
  .insert(allowance)
  .values({
    id: event.log.id,
    owner: event.args.owner,
    spender: event.args.spender,
    amount: event.args.amount,
  });
```

</div>

Here is a reference for how to migrate each method.

```ts filename="src/index.ts"
// create -> insert
await context.db.Account.create({
  id: event.args.from,
  data: { balance: 0n },
});
await context.db.insert(account).values({ id: event.args.from, balance: 0n });

// createMany -> insert
await context.db.Account.createMany({
  data: [
    { id: event.args.from, balance: 0n },
    { id: event.args.to, balance: 0n },
  ],
});
await context.db.insert(account).values([
  { id: event.args.from, balance: 0n },
  { id: event.args.to, balance: 0n },
]);

// findUnique -> find
await context.db.Account.findUnique({ id: event.args.from });
await context.db.find(account, { address: event.args.from });

// update
await context.db.Account.update({
  id: event.args.from,
  data: ({ current }) => ({ balance: current.balance + 100n }),
});
await context.db
  .update(account, { address: event.args.from })
  .set((row) => ({ balance: row.balance + 100n }));

// upsert
await context.db.Account.upsert({
  id: event.args.from,
  create: { balance: 0n },
  update: ({ current }) => ({ balance: current.balance + 100n }),
});
await context.db
  .insert(account)
  .values({ address: event.args.from, balance: 0n })
  .onConflictDoUpdate((row) => ({ balance: row.balance + 100n }));

// delete
await context.db.Account.delete({ id: event.args.from });
await context.db.delete(account, { address: event.args.from });

// findMany -> select
await context.db.Account.findMany({ where: { balance: { gt: 100n } } });
await context.db.sql.select().from(account).where(eq(account.balance, 100n));
```

Finally, another migration example for an ERC20 Transfer indexing function using `upsert`.

<div className="code-columns">

{/* prettier-ignore */}
```ts filename="src/index.ts"
import { ponder } from "@/generated";

ponder.on("ERC20:Transfer", async ({ event, context }) => {
  const { Account, TransferEvent } = context.db;

  await Account.upsert({
    id: event.args.from,
    create: {
      balance: BigInt(0),
      isOwner: false,
    },
    update: ({ current }) => ({
      balance: current.balance - event.args.amount,
    }),
  });
});
```

{/* prettier-ignore */}
```ts filename="src/index.ts"
import { ponder } from "@/generated";
import { account } from "../ponder.schema";

ponder.on("ERC20:Transfer", async ({ event, context }) => {
  await context.db
    .insert(account)
    .values({
      address: event.args.from,
      balance: 0n, 
      isOwner: false,
    })
    .onConflictDoUpdate((row) => ({
      balance: row.balance - event.args.amount,
    }));
});
```

</div>

#### Direct SQL API

The `context.db.sql` interface replaces the rigid `findMany` method and supports any valid SQL `select` query.

```ts filename="src/index.ts"
import { desc } from "@ponder/core";
import { account } from "../ponder.schema";

ponder.on("...", ({ event, context }) => {
  const result = await context.db.sql
    .select()
    .from(account)
    .orderBy(desc(account.balance))
    .limit(1);
});
```

### Migrate API functions

- Removed `c.tables` in favor of importing table objects from `ponder.schema.ts`

## 0.6.0

### Updated `viem` to `>=2`

This release updates the `viem` peer dependency requirement to `>=2`. The `context.client` action `getBytecode` was renamed to `getCode`.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm add viem@latest
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn add viem@latest
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm install viem@latest
```
</Tabs.Tab>
</Tabs>

### Simplified Postgres schema pattern

Starting with this release, the indexed tables, reorg tables, and metadata table for a Ponder app are contained in one Postgres schema, specified by the user in `ponder.config.ts` (defaults to `public`). This means the shared `ponder` schema is no longer used. (Note: The `ponder_sync` schema is still in use).

This release also removes the view publishing pattern and the `publishSchema` option from `ponder.config.ts`, which may disrupt production setups using horizontal scaling or direct SQL. If you relied on the publish pattern, please [get in touch on Telegram](https://t.me/kevinkoste) and we'll work to get you unblocked.

### Added `/ready`, updated `/health`

The new `/ready` endpoint returns an HTTP `200` response once the app **is ready to serve requests**. This means that historical indexing is complete and the app is indexing events in realtime.

The existing `/health` endpoint now returns an HTTP `200` response as soon as the process starts. (This release removes the `maxHealthcheckDuration` option, which previously governed the behavior of `/health`.)

For Railway users, we now recommend using `/ready` as the health check endpoint to enable zero downtime deployments. If your app takes a while to sync, be sure to set the healthcheck timeout accordingly. Read the [Railway deployment guide](/docs/production/deploy#railway) for more details.

### Metrics updates

Please see the [changelog](https://github.com/ponder-sh/ponder/blob/main/packages/core/CHANGELOG.md#060) for specifics.

## 0.5.0

### `hono` peer dependency

**Breaking:** This release adds [Hono](https://hono.dev) as a peer dependency. After upgrading, install `hono` in your project.

{/* prettier-ignore */}
<Tabs items={["pnpm", "yarn", "npm"]}>
  <Tabs.Tab>
```bash filename="shell"
pnpm add hono@latest
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
yarn add hono@latest
```
</Tabs.Tab>
  <Tabs.Tab>
```bash filename="shell"
npm install hono@latest
```
</Tabs.Tab>
</Tabs>

### Introduced API functions

This release added support for API functions. [Read more](/docs/query/api-functions).

## 0.4.0

This release changes the location of database tables when using both SQLite and Postgres.

It **does not** require any changes to your application code, and does not bust the sync cache for SQLite or Postgres.

Please read the new docs on [direct SQL](/docs/query/direct-sql) for a detailed overview.

### SQLite

Ponder now uses the `.ponder/sqlite/public.db` file for indexed tables. Before, the tables were present as views in the `.ponder/sqlite/ponder.db`. Now, the`.ponder/sqlite/ponder.db` file is only used internally by Ponder.

### Postgres

Ponder now creates a table in the `public` schema for each table in `ponder.schema.ts`. Before, Ponder created them as views in the `ponder` schema.

Isolation while running multiple Ponder instances against the same database also works differently. Before, Ponder used a schema with a pseudorandom name if the desired schema was in use. Now, Ponder will fail on startup with an error if it cannot acquire a lock on the desired schema.

This also changes the zero-downtime behavior on platforms like Railway. For more information on how this works in `0.4`, please reference:

- [Direct SQL](/docs/query/direct-sql)
- [Zero-downtime deployments](/docs/production/zero-downtime)

### Postgres table cleanup

After upgrading to `0.4.x`, you can run the following Postgres SQL script to clean up stale tables and views created by `0.3.x` Ponder apps.

**Note:** This script could obviously be destructive, so please read it carefully before executing.

```sql
DO $$
DECLARE
    view_name TEXT;
    schema_name_var TEXT;
BEGIN
    -- Drop all views from the 'ponder' schema
    FOR view_name IN SELECT table_name FROM information_schema.views WHERE table_schema = 'ponder'
    LOOP
        EXECUTE format('DROP VIEW IF EXISTS ponder.%I CASCADE', view_name);
        RAISE NOTICE 'Dropped view "ponder"."%"', view_name;
    END LOOP;

    -- Drop the 'ponder_cache' schema
    EXECUTE 'DROP SCHEMA IF EXISTS ponder_cache CASCADE';
    RAISE NOTICE 'Dropped schema "ponder_cache"';

    -- Find and drop any 'ponder_instance_*' schemas
    FOR schema_name_var IN SELECT schema_name AS schema_name_alias FROM information_schema.schemata WHERE schema_name LIKE 'ponder_instance_%'
    LOOP
        EXECUTE format('DROP SCHEMA IF EXISTS %I CASCADE', schema_name_var);
        RAISE NOTICE 'Dropped schema "%"', schema_name_var;
    END LOOP;
END $$;
```

## 0.3.0

No breaking API changes.

### Moved SQLite directory

**Note:** This release busted the SQLite sync cache.

The SQLite database was moved from the `.ponder/store` directory to `.ponder/sqlite`. The old `.ponder/store` directory will still be used by older versions.

### Moved Postgres sync tables

Similar to SQLite, the sync tables for Postgres were moved from the `public` schema to `ponder_sync`. Now, Ponder does not use the `public` schema whatsoever.

This change did NOT bust the sync cache; the tables were actually moved. This process emits some `WARN`-level logs that you should see after upgrading.

## 0.2.0

### Replaced `p.bytes()` with `p.hex()`

Removed `p.bytes()` in favor of a new `p.hex()` primitive column type. `p.hex()` is suitable for Ethereum addresses and other hex-encoded data, including EVM `bytes` types. `p.hex()` values are stored as `bytea` (Postgres) or `blob` (SQLite). To migrate, replace each occurence of `p.bytes()` in `ponder.schema.ts` with `p.hex()`, and ensure that any values you pass into hex columns are valid hexadecimal strings. The GraphQL API returns `p.hex()` values as hexadecimal strings, and allows sorting/filtering on `p.hex()` columns using the numeric comparison operators (`gt`, `gte`, `le`, `lte`).

### Cursor pagination

Updated the GraphQL API to use cursor pagination instead of offset pagination. Note that this change also affects the `findMany` database method. See the [GraphQL pagination docs](/docs/query/graphql#pagination) for more details.

## 0.1.0

Config

- In general, `ponder.config.ts` now has much more static validation using TypeScript. This includes network names in `contracts`, ABI event names for the contract `event` and `factory` options, and more.
- The `networks` and `contracts` fields were changed from an array to an object. The network or contract name is now specified using an object property name. The `name` field for both networks and contracts was removed.
- The `filter` field has been removed. To index all events matching a specific signature across all contract addresses, add a contract that specifies the `event` field without specifying an `address`.
- The `abi` field now requires an ABI object that has been asserted as const (cannot use a file path). See the ABIType documentation for more details.

Schema

- The schema definition API was rebuilt from scratch to use a TypeScript file `ponder.schema.ts` instead of `schema.graphql`. The `ponder.schema.ts` file has static validation using TypeScript.
- Note that it is possible to convert a `schema.graphql` file into a `ponder.schema.ts` file without introducing any breaking changes to the autogenerated GraphQL API schema.
- Please see the `design your schema` guide for an overview of the new API.

Indexing functions

- `event.params` was renamed to `event.args` to better match Ethereum terminology norms.
- If a contract uses the `event` option, only the specified events will be available for registration. Before, all events in the ABI were available.
- `context.models` was renamed to `context.db`
- Now, a read-only Viem client is available at `context.client`. This client uses the same transport you specify in `ponder.config.ts`, except all method are cached to speed up subsequent indexing.
- The `context.contracts` object now contains the contract addresses and ABIs specified in`ponder.config.ts`, typed as strictly as possible. (You should not need to copy addresses and ABIs around anymore, just use `context.contracts`).
- A new `context.network` object was added which contains the network name and chain ID that the current event is from.

Multi-chain indexing

- The contract `network` field `ponder.config.ts` was upgraded to support an object of network-specific overrides. This is a much better DX for indexing the same contract on multiple chains.
- The options that you can specify per-network are `address`, `event`, `startBlock`, `endBlock`, and `factory`.
- When you add a contract on multiple networks, Ponder will sync the contract on each network you specify. Any indexing functions you register for the contract will now process events across all networks.
- The `context.network` object is typed according to the networks that the current contract runs on, so you can write network-specific logic like `if (context.network.name === ‚Äúoptimism‚Äù) { ‚Ä¶`

Vite

- Ponder now uses Vite to transform and load your code. This means you can import files from outside the project root directory.
- Vite‚Äôs module graph makes it possible to invalidate project files granularly, only reloading the specific parts of your app that need to be updated when a specific file changes. For example, if you save a change to one of your ABI files, `ponder.config.ts` will reload because it imports that file, but your schema will not reload.
- This update also unblocks a path towards concurrent indexing and granular caching of indexing function results.

---
title: "Read contract data"
description: "Learn how to read contract data by calling read-only functions directly."
---

import { Callout } from "nextra/components";

# Read contract data

Ideally, smart contracts emit event logs containing all the data you need to build your application. In practice, developers often forget to include certain event logs, or omit them as a gas optimization. In some cases, you can address these gaps by reading data directly from a contract.

Ponder natively supports this pattern by injecting a custom [Viem Client](https://viem.sh/docs/clients/intro.html) into the indexing function context. This modified client automatically caches RPC requests and supports most standard Viem actions.

## Basic example

To read data from a contract, use `context.client.readContract(){:ts}` and include the contract address and ABI from `context.contracts`.

<div className="code-columns">

```ts filename="ponder.config.ts"
import { createConfig } from "ponder";
import { http } from "viem";

import { BlitmapAbi } from "./abis/Blitmap";

export default createConfig({
  networks: {
    mainnet: {
      chainId: 1,
      transport: http(process.env.PONDER_RPC_URL_1),
    },
  },
  contracts: {
    Blitmap: {
      network: "mainnet",
      abi: BlitmapAbi,
      address: "0x8d04...D3Ff63",
      startBlock: 12439123,
    },
  },
});
```

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";
import { tokens } from "ponder:schema";

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const { client } = context;
  //      ^? ReadonlyClient<"mainnet">
  const { Blitmap } = context.contracts;
  //      ^? {
  //           abi: [...]
  //           address: "0x8d04...D3Ff63",
  //         }

  // Fetch the URI for the newly minted token.
  const tokenUri = await client.readContract({
    abi: Blitmap.abi,
    address: Blitmap.address,
    functionName: "tokenURI",
    args: [event.args.tokenId],
  });

  // Insert a Token record, including the URI.
  await context.db.insert(tokens).values({
    id: event.args.tokenId,
    uri: tokenUri,
  });
});
```

</div>

## Client

The `context.client` object is a custom [Viem Client](https://viem.sh/docs/clients/intro.html) that caches requests by block number.

<Callout type="warning">
  **_Do not manually set up a viem Client._** If `context.client` is not working
  for you, please open a GitHub issue or send a message to the chat. We'd like
  to understand and accommodate your workflow.
</Callout>

<div className="code-columns">

```ts filename="src/index.ts"
// Don't do this! ‚ùå ‚ùå ‚ùå
import { createPublicClient, getContract, http } from "viem";

const publicClient = createPublicClient({
  transport: http("https://eth-mainnet.g.alchemy.com/v2/..."),
});

const Blitmap = getContract({
  address: "0x8d04...D3Ff63",
  abi: blitmapAbi,
  publicClient,
});

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const tokenUri = await Blitmap.read.tokenURI(event.args.tokenId);
});
```

```ts filename="src/index.ts"
// Do this instead. ‚úÖ ‚úÖ ‚úÖ

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const tokenUri = await context.client.readContract({
    abi: context.contracts.Blitmap.abi,
    address: context.contracts.Blitmap.address,
    method: "tokenUri",
    args: [event.args.tokenId],
  });
});
```

</div>

### Transport

The custom client uses the transport you specify in `ponder.config.ts`.

### Supported actions

| name                        | description                                                                                         | Viem docs                                                                                      |
| :-------------------------- | :-------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------- |
| readContract                | Returns the result of a read-only function on a contract.                                           | [readContract](https://viem.sh/docs/contract/readContract.html)                                |
| multicall                   | Similar to readContract, but batches requests.                                                      | [multicall](https://viem.sh/docs/contract/multicall.html)                                      |
| simulateContract            | Simulates & validates a contract interaction.                                                       | [simulateContract](https://viem.sh/docs/contract/simulateContract)                             |
| getBalance                  | Returns the balance of an address in wei.                                                           | [getBalance](https://viem.sh/docs/actions/public/getBalance.html)                              |
| getBytecode                 | Returns the bytecode at an address.                                                                 | [getBytecode](https://viem.sh/docs/contract/getBytecode.html)                                  |
| getStorageAt                | Returns the value from a storage slot at a given address.                                           | [getStorageAt](https://viem.sh/docs/contract/getStorageAt.html)                                |
| getBlock                    | Returns information about a block at a block number, hash or tag.                                   | [getBlock](https://viem.sh/docs/actions/public/getBlock)                                       |
| getTransactionCount         | Returns the number of transactions an account has broadcast / sent.                                 | [getTransactionCount](https://viem.sh/docs/actions/public/getTransactionCount)                 |
| getBlockTransactionCount    | Returns the number of Transactions at a block number, hash or tag.                                  | [getBlockTransactionCount](https://viem.sh/docs/actions/public/getBlockTransactionCount)       |
| getTransaction              | Returns information about a transaction given a hash or block identifier.                           | [getTransaction](https://viem.sh/docs/actions/public/getTransaction)                           |
| getTransactionReceipt       | Returns the transaction receipt given a transaction hash.                                           | [getTransactionReceipt](https://viem.sh/docs/actions/public/getTransactionReceipt)             |
| getTransactionConfirmations | Returns the number of blocks passed (confirmations) since the transaction was processed on a block. | [getTransactionConfirmations](https://viem.sh/docs/actions/public/getTransactionConfirmations) |
| call                        | An Action for executing a new message call.                                                         | [call](https://viem.sh/docs/actions/public/call)                                               |
| estimateGas                 | An Action for estimating gas for a transaction.                                                     | [estimateGas](https://viem.sh/docs/actions/public/estimateGas)                                 |
| getFeeHistory               | Returns a collection of historical gas information.                                                 | [getFeeHistory](https://viem.sh/docs/actions/public/getFeeHistory)                             |
| getProof                    | Returns the account and storage values of the specified account including the Merkle-proof.         | [getProof](https://viem.sh/docs/actions/public/getProof)                                       |
| getEnsAddress               | Gets address for ENS name.                                                                          | [getEnsAddress](https://viem.sh/docs/ens/actions/getEnsAddress)                                |
| getEnsAvatar                | Gets the avatar of an ENS name.                                                                     | [getEnsAvatar](https://viem.sh/docs/ens/actions/getEnsAvatar)                                  |
| getEnsName                  | Gets primary name for specified address.                                                            | [getEnsName](https://viem.sh/docs/ens/actions/getEnsName)                                      |
| getEnsResolver              | Gets resolver for ENS name.                                                                         | [getEnsResolver](https://viem.sh/docs/ens/actions/getEnsResolver)                              |
| getEnsText                  | Gets a text record for specified ENS name.                                                          | [getEnsText](https://viem.sh/docs/ens/actions/getEnsText)                                      |

### Block number

By default, the `blockNumber` option is set to the block number of the current event (`event.block.number`).

```ts filename="src/index.ts" {8-9}
import { ponder } from "ponder:registry";

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const totalSupply = await context.client.readContract({
    abi: context.contracts.Blitmap.abi,
    address: context.contracts.Blitmap.address,
    functionName: "totalSupply",
    // This is set automatically, no need to include it youself.
    // blockNumber: event.block.number,
  });
});
```

You can also specify a `blockNumber` to read data at a specific block height. It will still be cached.

```ts filename="src/index.ts" {8}
import { ponder } from "ponder:registry";

ponder.on("Blitmap:Mint", async ({ event, context }) => {
  const totalSupply = await context.client.readContract({
    abi: context.contracts.Blitmap.abi,
    address: context.contracts.Blitmap.address,
    functionName: "totalSupply",
    blockNumber: 15439123n,
  });
});
```

<Callout>
  The `blockTag` option is not supported by custom client actions.
</Callout>

### Caching

To speed up indexing and avoid unnecessary RPC requests, all method calls are cached. When an indexing function calls a method with a specific set of arguments for the first time, it will make an RPC request. Any subsequent calls to the same method with the same arguments will be served from the cache.

## Contract addresses & ABIs

The `context.contracts` object contains each contract address and ABI you provide in `ponder.config.ts`.

### Multiple networks

If a contract is configured to run on multiple networks, `context.contracts` contains the contract addresses for whichever network the current event is from.

<Callout type="info">
  It's not currently possible to call a contract that's on a different network
  than the current event. If you need this feature, please open an issue or send
  a message to the chat.
</Callout>

<div className="code-columns">

```ts filename="ponder.config.ts" {14-23}
import { createConfig } from "ponder";
import { http } from "viem";

import { UniswapV3FactoryAbi } from "./abis/UniswapV3Factory";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
    base: { chainId: 8453, transport: http(process.env.PONDER_RPC_URL_8453) },
  },
  contracts: {
    UniswapV3Factory: {
      abi: UniswapV3FactoryAbi,
      network: {
        mainnet: {
          address: "0x1F98431c8aD98523631AE4a59f267346ea31F984",
          startBlock: 12369621,
        },
        base: {
          address: "0x33128a8fC17869897dcE68Ed026d694621f6FDfD",
          startBlock: 1371680,
        },
      },
    },
  },
});
```

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";

ponder.on("UniswapV3Factory:FeeAmountEnabled", async ({ event, context }) => {
  const tickSpacing = await context.client.readContract({
    abi: context.contracts.UniswapV3Factory.abi,
    address: context.contracts.UniswapV3Factory.address,
    functionName: "feeAmountTickSpacing",
    args: [event.args.fee],
  });
});
```

</div>

### Factory contracts

Contracts that are created by a factory have a dynamic address, so the `context.contracts` object does not have an `address` property. To read data from the contract that emitted the current event, use `event.log.address`.

```ts filename="src/index.ts" {9}
import { ponder } from "ponder:registry";

ponder.on("SudoswapPool:Transfer", async ({ event, context }) => {
  const { SudoswapPool } = context.contracts;
  //      ^? { abi: [...] }

  const totalSupply = await context.client.readContract({
    abi: SudoswapPool.abi,
    address: event.log.address,
    functionName: "totalSupply",
  });
});
```

To call a factory contract child from an indexing function for a _different_ contract, use your application logic to determine the correct address to enter. For example, the address might come from `event.args`.

```ts filename="src/index.ts" {6}
import { ponder } from "ponder:registry";

ponder.on("FancyLendingProtocol:RegisterPool", async ({ event, context }) => {
  const totalSupply = await context.client.readContract({
    abi: context.contracts.SudoswapPool.abi,
    address: event.args.pool,
    functionName: "totalSupply",
  });
});
```

### Read a contract without indexing it

The `context.contracts` object only contains addresses & ABIs for the contracts in `ponder.config.ts`.

To read from a contract without syncing & indexing event logs from it, import the ABI object directly into an indexing function file and include the address manually. One-off requests like this are still cached and the `blockNumber` is set automatically.

<div className="code-columns">

```ts filename="ponder.config.ts"
import { createConfig } from "ponder";

import { AaveTokenAbi } from "./abis/AaveToken";

export default createConfig({
  contracts: {
    AaveToken: {
      network: "mainnet",
      abi: AaveTokenAbi,
      address: "0x7Fc66500c84A76Ad7e9c93437bFc5Ac33E2DDaE9",
      startBlock: 10926829,
    },
  },
});
```

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";

import { ChainlinkPriceFeedAbi } from "../abis/ChainlinkPriceFeed";

ponder.on("AaveToken:Mint", async ({ event, context }) => {
  const priceData = await context.client.readContract({
    abi: ChainlinkPriceFeedAbi,
    address: "0x547a514d5e3769680Ce22B2361c10Ea13619e8a9",
    functionName: "latestRoundData",
  });

  const usdValue = priceData.answer * event.args.amount;
  // ...
});
```

</div>

## More examples

### Zorbs gradient data

Suppose we're building an application that stores the gradient metadata of each [Zorb NFT](https://etherscan.io/address/0xca21d4228cdcc68d4e23807e5e370c07577dd152#code). Here's a snippet from the contract.

```solidity filename="ZorbNft.sol" {7-9}
contract ZorbNft is ERC721 {

    function mint() public {
        // ...
    }

    function gradientForAddress(address user) public pure returns (bytes[5] memory) {
        return ColorLib.gradientForAddress(user);
    }
}
```

Every Zorb has a gradient, but the contract doesn't emit gradient data in any event logs (it only emits events required by ERC721). The gradient data for a given Zorb can, however, be accessed using the `gradientForAddress` function.

```ts filename="src/index.ts" {6-11}
import { ponder } from "ponder:registry";
import { zorbs } from "ponder:schema";

ponder.on("ZorbNft:Transfer", async ({ event, context }) => {
  if (event.args.from === ZERO_ADDRESS) {
    // If this is a mint, read gradient metadata from the contract.
    const gradientData = await context.client.readContract({
      abi: context.contracts.ZorbNft.abi,
      address: context.contracts.ZorbNft.address,
      functionName: "gradientForAddress",
      args: [event.args.to],
    });

    await context.db.insert(zorbs).values({
      id: event.args.tokenId,
      gradient: gradientData,
      ownerId: event.args.to,
    });
  } else {
    // If not a mint, just update ownership information.
    await context.db
      .update(zorbs, { id: event.args.tokenId })
      .set({ ownerId: event.args.to });
  }
});
```

---
title: "Write to the database"
description: "Learn how to insert, update, and delete rows in the database."
---

import { Callout } from "nextra/components";

# Write to the database

The purpose of indexing functions is to write application-ready data to the database. Ponder has two reorg-resistant database interfaces: the **store API** and **raw SQL**.

## Store API

The store API is a SQL-like query builder optimized for EVM indexing workloads. It's less flexible than raw SQL, but is often several orders of magnitude faster.

<details>
  <summary><p>The examples below use this `ponder.schema.ts`.</p></summary>
  <p />

```ts filename="ponder.schema.ts"
import { onchainTable, primaryKey } from "ponder";

export const accounts = onchainTable("accounts", (t) => ({
  address: t.hex().primaryKey(),
  balance: t.bigint().notNull(),
  nickname: t.text(),
}));

export const allowances = onchainTable(
  "allowances",
  (t) => ({
    owner: t.hex().notNull(),
    spender: t.hex().notNull(),
    value: t.bigint().notNull(),
  }),
  (table) => ({
    pk: primaryKey({ columns: [table.owner, table.spender] }),
  })
);
```

</details>

### `insert`

Insert one or many rows into the database. Returns the inserted rows, **including** any default values that were generated.

{/* prettier-ignore */}
```ts filename="src/index.ts"
import { accounts } from "ponder:schema";

const row = await db.insert(accounts).values({
  address: "0x7Df1", balance: 0n
});

const rows = await db.insert(accounts).values([
  { address: "0x7Df2", balance: -50n },
  { address: "0x7Df3", balance: 100n },
]);
```

If you insert a row that violates a not null constraint, `insert` will reject with an error.

```ts filename="src/index.ts" {7}
import { tokens } from "ponder:schema";

const row = await db.insert(accounts).values({
  address: "0x7Df1",
});

// Error: Column "balance" is required but not present in the values object.
```

### `find`

Find a single row by primary key. Returns the row, or `null` if no matching row is found.

```ts filename="src/index.ts"
import { accounts } from "ponder:schema";

const row = await db.find(accounts, { address: "0x7Df1" });
```

If the table has a composite primary key, the second argument is an object including all the primary key values.

```ts filename="src/index.ts"
import { allowances } from "ponder:schema";

const row = await db.find(allowances, { owner: "0x7Df1", spender: "0x7Df2" });
```

### `update`

Update a row by primary key. Returns the updated row.

```ts filename="src/index.ts"
import { accounts } from "ponder:schema";

const row = await db
  .update(accounts, { address: "0x7Df1" })
  .set({ balance: 100n });
```

You can also pass a function to `set` which receives the existing row and returns the update object.

```ts filename="src/index.ts" {5}
import { accounts } from "ponder:schema";

const row = await db
  .update(accounts, { address: "0x7Df1" })
  .set((row) => ({ balance: row.balance + 100n }));
```

If the target row is not found, `update` will reject with an error.

```ts filename="src/index.ts" {7}
import { tokens } from "ponder:schema";

const row = await db
  .update(accounts, { address: "0x7Df1" })
  .set({ balance: null });

// Error: No row found for address "0x7Df1".
```

If the new row violates a not null constraint, `update` will reject with an error.

```ts filename="src/index.ts" {7}
import { tokens } from "ponder:schema";

const row = await db
  .update(accounts, { address: "0x7Df1" })
  .set({ balance: null });

// Error: Column "balance" is required but not present in the object.
```

### `delete`

Delete a row by primary key. Returns `true` if the row was deleted, or `false` if no matching row was found.

```ts filename="src/index.ts"
import { accounts } from "ponder:schema";

const deleted = await db.delete(accounts, { address: "0x7Df1" });
```

### Upsert & conflict resolution

If you insert a duplicate row that violates the table's primary key constraint, `insert` will reject with an error. Use `onConflictDoNothing` to skip the insert operation if a row with the same primary key already exists.

```ts filename="src/index.ts" {6}
import { accounts } from "ponder:schema";

const row = await db
  .insert(accounts)
  .values({ address: "0x7Df1", balance: 0n })
  .onConflictDoNothing();
```

Or, perform an **upsert** with `onConflictDoUpdate`.

```ts filename="src/index.ts" {6}
import { accounts } from "ponder:schema";

const row = await db
  .insert(accounts)
  .values({ address: "0x7Df1", balance: 0n, activeAt: event.block.timestamp })
  .onConflictDoUpdate({ activeAt: event.block.timestamp });
```

Like `update`, you can pass a function to `onConflictDoUpdate` which receives the existing row and returns the update object.

```ts filename="src/index.ts" {6}
import { accounts } from "ponder:schema";

const row = await db
  .insert(accounts)
  .values({ address: "0x7Df1", balance: 0n })
  .onConflictDoUpdate((row) => ({ balance: row.balance + 100n }));
```

Both `onConflictDoNothing` and `onConflictDoUpdate` also work when inserting many rows at once. The conflict resolution logic gets applied to each row individually.

```ts filename="src/index.ts"
import { accounts } from "ponder:schema";

const rows = await db
  .insert(accounts)
  .values([
    { address: "0x7Df1", balance: 0n },
    { address: "0x7Df2", balance: 100n },
  ])
  .onConflictDoNothing();
```

### How it works

EVM indexing workloads often involve a large number of small inserts and updates. To mitigate the performance penalty of many (blocking) database queries, the store API runs **in-memory** during historical indexing.

When the in-memory cache exceeds a certain size, the store flushes all pending data to the database using one `COPY{:sql}` statement per table. During development, the store also flushes every 5 seconds regardless of size to ensure that the database state is reasonably up-to-date to support ad-hoc queries.

## Raw SQL

<Callout type="warning">
  Raw SQL queries are **much slower** than the store API. Avoid raw SQL for
  indexing logic that runs often.
</Callout>

The constraints of the store API make it difficult to implement complex business logic. In these cases, you can drop down to raw SQL.

### Query builder

The `db.sql` object exposes the raw Drizzle PostgreSQL query builder, including the `select`, `insert`, `update`, and `delete` functions. Visit the [Drizzle docs](https://orm.drizzle.team/docs/select) for more information and a detailed API reference.

Here's an example that uses the raw SQL `update` function to execute a complex bulk update query.

```ts filename="src/index.ts"
import { ponder } from "ponder:registry";
import { accounts, tradeEvents } from "ponder:schema";
import { eq, and, gte, inArray, sql } from "drizzle-orm";

// Add 100 points to all accounts that submitted a trade in the last 24 hours.
ponder.on("EveryDay:block", async ({ event, context }) => {
  await db.sql
    .update(accounts)
    .set({ points: sql`${accounts.points} + 100` })
    .where(
      inArray(
        accounts.address,
        db.sql
          .select({ address: tradeEvents.from })
          .from(tradeEvents)
          .where(
            gte(tradeEvents.timestamp, event.block.timestamp - 24 * 60 * 60)
          )
      )
    );
});
```

### Relational queries

Drizzle's relational query builder (AKA Drizzle Queries) offers a great developer experience for complex `SELECT{:sql}` queries that join multiple tables. The `db.sql.query` object exposes the raw Drizzle relational query builder. Visit the [Drizzle Queries docs](https://orm.drizzle.team/docs/rqb) for more details.

Here's an example that uses the relational query builder in an API function to find the 10 largest trades in the past hour joined with the account that made the trade.

```ts filename="src/api/index.ts"
import { eq, and, gte, inArray, sql } from "drizzle-orm";
import { accounts, tradeEvents } from "ponder:schema";

ponder.get("/hot-trades", async (c) => {
  const trades = await c.db.query.tradeEvents.findMany({
    where: (table, { gt, gte, and }) =>
      and(
        gt(table.amount, 1_000n),
        gte(table.timestamp, Date.now() - 1000 * 60 * 60)
      ),
    limit: 10,
    with: { account: true },
  });

  return c.json(trades);
});
```

---
title: "API functions"
description: "Use API functions to customize the API layer of your app."
---

import { Callout, Steps } from "nextra/components";

# API functions

**API functions** are user-defined TypeScript functions that handle web requests. You can use them to customize the API layer of your app with complex SQL queries, authentication, data from external sources, and more.

API functions are built on top of [Hono](https://hono.dev/), a fast and lightweight routing framework.

## Example projects

These example apps demonstrate how to use API functions.

- [**Basic**](https://github.com/ponder-sh/ponder/tree/main/examples/feature-api-functions/src/api/index.ts) - An ERC20 app that responds to `GET` requests and uses [Drizzle](#query-the-database) to build custom SQL queries.
- [**tRPC**](https://github.com/ponder-sh/ponder/tree/main/examples/with-trpc/client/index.ts) - An app that creates a [tRPC](https://trpc.io) server and a script that uses a tRPC client with end-to-end type safety.

## Get started

<Steps>

### Upgrade to `>=0.5.0`

API functions are available starting from version `0.5.0`. Read the [migration guide](/docs/migration-guide#050) for more details.

### Create `src/api/index.ts` file

To enable API functions, create a file named `src/api/index.ts` with the following code. You can register API functions in any `.ts` file in the `src/api/` directory.

```ts filename="src/api/index.ts"
import { ponder } from "ponder:registry";

ponder.get("/hello", (c) => {
  return c.text("Hello, world!");
});
```

### Send a request

Visit `http://localhost:42069/hello` in your browser to see the response.

```plaintext filename="Response"
Hello, world!
```

### Register GraphQL middleware

<Callout type="warning">
  Once you create an API function file, you have "opted in" to API functions and
  your app **will not** serve the standard GraphQL API by default.
</Callout>

To continue using the standard GraphQL API, register the `graphql` middleware exported from `ponder`.

```ts filename="src/api/index.ts" {2,4-5}
import { ponder } from "ponder:registry";
import { graphql } from "ponder";

ponder.use("/", graphql());
ponder.use("/graphql", graphql());

// ...
```

</Steps>

## Query the database

The API function context includes a ready-to-use Drizzle database client at `c.db`. To query the database, import table objects from `ponder.schema.ts` and pass them to `c.db.select()` or use relational queries.

### Select

Here's a simple query using the Drizzle `select` query builder.

```ts filename="src/api/index.ts"
import { ponder } from "ponder:registry";
import { accounts } from "ponder:schema";

ponder.get("/account/:address", async (c) => {
  const address = c.req.param("address");

  const account = await c.db
    .select()
    .from(accounts)
    .where(eq(accounts.address, address))
    .limit(1);

  return c.json(account);
});
```

To build more complex queries, use `join`, `groupBy`, `where`, `orderBy`, `limit`, and other methods. Drizzle's filter & conditional operators (like `eq`, `gte`, and `or`) are re-exported by `ponder`. Visit the Drizzle [documentation](https://orm.drizzle.team/docs/select) for more details.

### Relational queries

Drizzle's relational query builder (AKA Drizzle Queries) offers a great developer experience for complex queries. The `c.db.query` object exposes the raw Drizzle relational query builder.

Here's an example that uses the relational query builder in an API function to find the 10 largest trades in the past hour joined with the account that made the trade. Visit the Drizzle Queries [documentation](https://orm.drizzle.team/docs/rqb) for more details.

```ts filename="src/api/index.ts"
import { accounts, tradeEvents } from "ponder:schema";
import { eq, and, gte, inArray, sql } from "drizzle-orm";

ponder.get("/hot-trades", async (c) => {
  const trades = await c.db.query.tradeEvents.findMany({
    where: (table, { gt, gte, and }) =>
      and(
        gt(table.amount, 1_000n),
        gte(table.timestamp, Date.now() - 1000 * 60 * 60)
      ),
    limit: 10,
    with: { account: true },
  });

  return c.json(trades);
});
```

## API reference

### `get()`

Use `ponder.get()` to handle HTTP `GET` requests. The `c` context object contains the request, response helpers, and the database connection.

```ts filename="src/api/index.ts" {5}
import { ponder } from "ponder:registry";
import { accounts } from "ponder:schema";
import { eq } from "ponder";

ponder.get("/account/:address", async (c) => {
  const address = c.req.param("address");

  const account = await c.db
    .select()
    .from(accounts)
    .where(eq(accounts.address, address))
    .first();

  if (account) {
    return c.json(account);
  } else {
    return c.status(404).json({ error: "Account not found" });
  }
});
```

### `post()`

<Callout type="info">
  API functions cannot write to the database, even when handling `POST`
  requests.
</Callout>

Use `ponder.post()` to handle HTTP `POST` requests.

In this example, we calculate the volume of transfers for each recipient within a given time range. The `fromTimestamp` and `toTimestamp` parameters are passed in the request body.

```ts filename="src/api/index.ts" {5}
import { ponder } from "ponder:registry";
import { transferEvents } from "ponder:schema";
import { and, gte, sum } from "ponder";

ponder.post("/volume", async (c) => {
  const body = await c.req.json();
  const { fromTimestamp, toTimestamp } = body;

  const volumeChartData = await c.db
    .select({
      to: transferEvents.toId,
      volume: sum(transferEvents.amount),
    })
    .from(transferEvents)
    .groupBy(transferEvents.toId)
    .where(
      and(
        gte(transferEvents.timestamp, fromTimestamp),
        lte(transferEvents.timestamp, toTimestamp)
      )
    )
    .limit(1);

  return c.json(volumeChartData);
});
```

### `use()`

Use `ponder.use(...){:ts}` to add middleware to your API functions. Middleware functions can modify the request and response objects, add logs, authenticate requests, and more. [Read more](https://hono.dev/docs/guides/middleware) about Hono middleware.

```ts filename="src/api/index.ts" {3}
import { ponder } from "ponder:registry";

ponder.use((c, next) => {
  console.log("Request received:", c.req.url);
  return next();
});
```

### `hono`

Use `ponder.hono` to access the underlying Hono instance.

```ts filename="src/api/index.ts" {3}
import { ponder } from "ponder:registry";

ponder.hono.notFound((c) => {
  return c.text("Custom 404 Message", 404);
});

// ...
```

## Reserved routes

If you register API functions that conflict with these internal routes, the build will fail.

- `/health`: Returns a `200` status code immediately after the app starts running. [Read more](/docs/production/deploy#healthchecks) about healthchecks.
- `/ready`: Returns a `200` status code after the app has completed the historical backfill and is available to serve traffic. [Read more](/docs/production/deploy#healthchecks) about heatlthchecks.
- `/metrics`: Returns Prometheus metrics. [Read more](/docs/advanced/metrics) about metrics.
- `/status`: Returns indexing status object. [Read more](/docs/advanced/status) about indexing status.

---
title: "Direct SQL"
description: "How to query the Ponder database"
---

import { Callout, FileTree, Steps } from "nextra/components";

# Direct SQL queries

This guide describes how to query the database directly using psql or Drizzle.

<Callout type="warning">
  Don't write to onchain tables from external clients. Only write to onchain
  tables from indexing functions.
</Callout>

<Callout type="info">
  Direct SQL queries against PGlite are
  [possible](https://github.com/supabase-community/pg-gateway?tab=readme-ov-file#pglite),
  but the methods described here do not work out of the box.
</Callout>

## psql

You can also use [psql](https://www.postgresql.org/docs/current/app-psql.html), a terminal-based Postgres front-end, to query the database from the command line.

<Steps>

### Connection string

Connect using the same connection string that your Ponder app uses.

```bash filename="shell"
psql 'postgresql://username:password@localhost:5432/your_database'
```

### Display tables

Use the `\dt` command to list all tables in the `public` schema. If you are using a schema other than `public`, include the pattern.

<div className="code-columns">

```bash filename="psql"
\dt
```

```bash filename="psql"
\dt my_schema.*
```

</div>

The `reorg` tables are used by Ponder internally during reorg reconciliation, and the `_ponder_meta` table is used to store metadata about the database state.

```plaintext filename="psql (result)"
                    List of relations
 Schema | Name                        | Type  | Owner
--------+-----------------------------+-------+----------
 public | accounts                    | table | username
 public | transfer_events             | table | username
 public | _ponder_meta                | table | username
 public | _reorg__accounts            | table | username
 public | _reorg__transfer_events     | table | username
(5 rows)
```

### Select rows

Select a few rows from the `accounts` table.

```sql filename="psql"
SELECT * FROM accounts LIMIT 5;
```

```plaintext filename="psql (result)"
                  address                   |         balance         |
--------------------------------------------+-------------------------+
 0xf73fe15cfb88ea3c7f301f16ade3c02564aca407 | 10000000000000000000000 |
 0xb0659bc97ed61b37d6b140f3e12a41d471781714 | 20000000000000000000000 |
 0x52932f5b2767d917c3134140168f2176c94e8b2c | 10000000000000000000000 |
 0xfb7ca75b3ce099120602b5ab7104cff030ee43f8 |                       0 |
 0x9ccc6c5a9d25429f55ad9af6363c1c4f16b179ad |  7000000000000000000000 |
(5 rows)
```

### Aggregate data

Find the total number of transfers sent to each account.

```sql filename="psql"
SELECT "to", COUNT(*) AS transfer_count
  FROM transfer_events
  GROUP BY "to"
  ORDER BY transfer_count DESC
  LIMIT 5;
```

```plaintext filename="psql (result)"
                     to                     | transfer_count
--------------------------------------------+----------------
 0x5d752f322befb038991579972e912b02f61a3dda |           2342
 0x1337f7970e8399ccbc625647fce58a9dada5aa66 |            313
 0x9726041047644626468922598128349778349982 |            306
 0x27239549dd40e1d60f5b80b0c4196923745b1fd2 |            256
 0x450638daf0caedbdd9f8cb4a41fa1b24788b123e |            238
(5 rows)
```

</Steps>

## Drizzle

<Callout type="warning">
  As of `0.8`, the `onchainTable` objects are not automatically aware of the
  database schema that your instance is using. To get this working, you'll need
  to 1) use the `public` schema or 2) set the connection search path to the
  schema that your instance is using. We're tracking this issue
  [here](https://github.com/ponder-sh/ponder/issues/1325).
</Callout>

The `onchainTable` objects exported by `ponder.schema.ts` are valid Drizzle table objects. You can import them from TypeScript files outside the Ponder `src/` directory and use them with the Drizzle query builder.

Here's a script that creates a Drizzle client and runs a query against the Ponder tables. Be sure to connect to the database using the same `DATABASE_URL` as the Ponder app.

```ts filename="query.ts"
import { drizzle } from "drizzle-orm/node-postgres";
import * as schema from "../../ponder/ponder.schema";

const db = drizzle(process.env.DATABASE_URL, { schema, casing: "snake_case" });

// Select
const oldAccounts = await db
  .select()
  .from(schema.accounts)
  .orderBy(asc(schema.accounts.createdAt))
  .limit(100);

// Query
const whalesWithTransfers = await db.query.accounts.findMany({
  where: (accounts, { eq }) => eq(accounts.balance, 1_000_000n),
  with: { transferEvents: true },
});
```

---
title: "Query the GraphQL API"
description: "Learn how to sort, filter and paginate data using the Ponder GraphQL API."
---

import { Callout } from "nextra/components";

# Query the GraphQL API

<Callout type="info">
  This guide assumes you have a working knowledge of GraphQL. Visit the
  [documentation](https://graphql.org/learn/) for an overview.
</Callout>

Ponder automatically generates a GraphQL schema based on your `ponder.schema.ts` file that uses efficient resolver logic to avoid common performance pitfalls.

## GraphiQL

With the dev server running, open `http://localhost:42069` in your browser to use the [GraphiQL](https://github.com/graphql/graphiql/tree/main/packages/graphiql#graphiql) interface. GraphiQL is a useful tool for exploring your schema and testing queries during development.

## Schema generation

The GraphQL schema includes a **singular** and a **plural** query field for each table in `ponder.schema.ts`.

If your schema contains a `person` table, the GraphQL schema will include a `person` and a `persons` field on the root `Query` type. The singular query field returns a single record (or null) and the plural query field returns a page of records.

<div className="code-columns">

```ts filename="ponder.schema.ts"
import { onchainTable } from "ponder";

export const person = onchainTable("person", (t) => ({
  id: t.integer().primaryKey(),
  name: t.text().notNull(),
  age: t.integer(),
}));
```

{/* prettier-ignore */}
```graphql filename="Generated schema"
type Query {
  person(id: Int!, timestamp: Int): person
  persons(
    where: personFilter, 
    orderBy: String,
    orderDirection: String,
    before: String,
    after: String,
    limit: Int,
    timestamp: Int,
  ): personPage!
}

type person {
  id: Int!
  name: String!
  age: Int
}

type personPage {
  items: [person!]!
  pageInfo: PageInfo!
  totalCount: Int!
}
```

</div>

## Filtering

Use the `where` argument to filter for records that match certain criteria. The `where` argument type includes filter options for every column defined on a table. Here are the filter options available for each column type.

| Filter option              | Available for column types    | _Include records where \{column\}..._     |
| :------------------------- | :---------------------------- | :---------------------------------------- |
| `{column}`                 | All                           | **equals** the value                      |
| `{column}_not`             | All                           | **does not equal** the value              |
| `{column}_in`              | All primitives and enums      | **is one of** the values                  |
| `{column}_not_in`          | All primitives and enums      | **is not one of** the values              |
| `{column}_gt`              | Numeric primitives            | is **greater than** the value             |
| `{column}_lt`              | Numeric primitives            | is **less than** the value                |
| `{column}_gte`             | Numeric primitives            | is **greater than or equal to** the value |
| `{column}_lte`             | Numeric primitives            | is **less than or equal to** the value    |
| `{column}_contains`        | String primitives             | **contains** the substring                |
| `{column}_not_contains`    | String primitives             | **does not contain** the substring        |
| `{column}_starts_with`     | String primitives             | **starts with** the substring             |
| `{column}_not_starts_with` | String primitives             | **does not start with** the substring     |
| `{column}_ends_with`       | String primitives             | **ends with** the substring               |
| `{column}_not_ends_with`   | String primitives             | **does not end with** the substring       |
| `{column}_has`             | Lists of primitives and enums | **has** the value as an element           |
| `{column}_not_has`         | Lists of primitives and enums | **does not have** the value as an element |

You can compose filters using the `AND` and `OR` operators. These special fields accept an array of filter objects.

### Examples

For the following examples, assume these records exist in your database.

<div className="code-columns">
{/* prettier-ignore */}
```json filename="person data"
[
  { "id": 1, "name": "Barry", "age": 57 },
  { "id": 2, "name": "Lucile", "age": 32 },
  { "id": 3, "name": "Sally", "age": 22 },
  { "id": 4, "name": "Pablo", "age": 71 },
]
```
<div></div>
</div>

Get all `person` records with an `age` greater than `32`.

<div className="code-columns">
{/* prettier-ignore */}
```graphql filename="Query"
query {
  persons(where: { age_gt: 32 }) {
    name
    age
  }
}
```

{/* prettier-ignore */}
```json filename="Result"
{
  "persons": [
    { "name": "Barry", "age": 57 },
    { "name": "Pablo", "age": 71 },
  ]
}
```

</div>

Get all `person` records with a `name` that does not end with `"y"` _and_ an age greater than `60`. Note that when you include multiple filter conditions, they are combined with a logical `AND`.

<div className="code-columns">
{/* prettier-ignore */}
```graphql filename="Query"
query {
  persons(
    where: {
      AND: [
        { name_not_ends_with: "y" },
        { age_gte: 60 }
      ]
    }
  ) {
    name
    age
  }
}
```

{/* prettier-ignore */}
```json filename="Result"
{
  "persons": [
    { "name": "Pablo", "age": 71 },
  ]
}
```

</div>

Get all `person` records with a `name` that contains `"ll"` _or_ an age greater than or equal to `50`. In this case, we use the special `OR` operator to combine multiple filter conditions.

<div className="code-columns">
{/* prettier-ignore */}
```graphql filename="Query"
query {
  persons(
    where: {
      OR: [
        { name_contains: "ll" },
        { age_gte: 50 }
      ] 
    }
  ) {
    name
    age
  }
}
```

{/* prettier-ignore */}
```json filename="Result"
{
  "persons": [
    { "name": "Barry", "age": 57 },
    { "name": "Sally", "age": 22 },
    { "name": "Pablo", "age": 71 },
  ]
}
```

</div>

## Sorting

Use the `orderBy` and `orderDirection` arguments to sort records by a column. `string` values are sorted lexicographically.

| Pagination option | Default |
| :---------------- | :------ |
| `orderBy`         | `"id"`  |
| `orderDirection`  | `"asc"` |

### Examples

<div className="code-columns">
{/* prettier-ignore */}
```graphql filename="Query"
query {
  persons(orderBy: "age", orderDirection: "desc") {
    name
    age
  }
}
```

{/* prettier-ignore */}
```json filename="Result"
{
  "persons": [
    { "name": "Pablo", "age": 71 },
    { "name": "Barry", "age": 57 },
    { "name": "Lucile", "age": 32 },
    { "name": "Sally", "age": 22 },
  ]
}
```

</div>

## Pagination

The GraphQL API supports cursor pagination with an API that's inspired by the [Relay GraphQL Cursor Connection](https://relay.dev/graphql/connections.htm#sec-undefined.PageInfo) specification.

Plural fields and `p.many()` relationship fields each return a `Page` type. This object contains a list of items, a `PageInfo` object, and the total count of records that match the query.

<div className="code-columns">
```ts filename="ponder.schema.ts"
import { onchainTable } from "ponder";

export const pet = onchainTable("pet", (t) => ({
  id: t.text().primaryKey(),
  name: t.text().notNull(),
}));
```

{/* prettier-ignore */}
```graphql filename="Generated schema" {1-5}
type petPage {
  items: [pet!]!
  pageInfo: PageInfo!
  totalCount: Int!
}

type pet {
  id: String!
  name: String!
}

type PageInfo {
  startCursor: String
  endCursor: String
  hasPreviousPage: Boolean!
  hasNextPage: Boolean!
}
```

</div>

### Page info

The `PageInfo` object contains information about the position of the current page within the result set.

| name                | type                 |                                                 |
| :------------------ | :------------------- | :---------------------------------------------- |
| **startCursor**     | `String{:graphql}`   | Cursor of the first record in `items`           |
| **endCursor**       | `String{:graphql}`   | Cursor of the last record in `items`            |
| **hasPreviousPage** | `Boolean!{:graphql}` | Whether there are more records before this page |
| **hasNextPage**     | `Boolean!{:graphql}` | Whether there are more records after this page  |

### Total count

The `totalCount` field returns the number of records present in the database that match the specified query. The value the same value regardless of the current pagination position and the `limit` argument. Only the `where` argument can change the value of `totalCount`.

<Callout type="warning">
  The SQL query that backs `totalCount` can be slow. To avoid performance
  issues, include `totalCount` in the query for the first page, then exclude it
  for subsequent pages. Unless the underlying data has changed, the value will
  be the same regardless of the pagination position.
</Callout>

### Cursor values

A cursor value is an opaque string that encodes the position of a record in the result set.

- Cursor values should not be decoded or manipulated by the client. The only valid use of a cursor value is an argument, e.g. `after: previousPage.endCursor{:ts}`.
- Cursor pagination works with any filter and sort criteria. However, do not change the filter or sort criteria between paginated requests. This will cause validation errors or incorrect results.

### Examples

As a reminder, assume that these records exist in your database for the following examples.

<div className="code-columns">
{/* prettier-ignore */}
```json filename="person data"
[
  { "id": 1, "name": "Barry", "age": 57 },
  { "id": 2, "name": "Lucile", "age": 32 },
  { "id": 3, "name": "Sally", "age": 22 },
  { "id": 4, "name": "Pablo", "age": 71 },
]
```
</div>

First, make a request without specifying any pagination options. The `items` list will contain the first `n=limit` records that match the filter and sort criteria.

<div className="code-columns">
```graphql filename="Query one"
query {
  persons(orderBy: "age", orderDirection: "asc", limit: 2) {
    items {
      name
      age
    }
    pageInfo {
      startCursor
      endCursor
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

{/* prettier-ignore */}
```json filename="Result one"
{
  "persons" {
    "items": [
      { "name": "Sally", "age": 22 },
      { "name": "Lucile", "age": 32 },
    ],
    "pageInfo": {
      "startCursor": "MfgBzeDkjs44",
      "endCursor": "Mxhc3NDb3JlLTA=",
      "hasPreviousPage": false,
      "hasNextPage": true,
    },
    "totalCount": 4,
  }
}
```

</div>

To paginate forwards, pass `pageInfo.endCursor` from the previous request as the `after` option in the next request.

<div className="code-columns">
```graphql filename="Query one" {6}
query {
  persons(
    orderBy: "age",
    orderDirection: "asc",
    limit: 2,
    after: "Mxhc3NDb3JlLTA="
  ) {
    items {
      name
      age
    }
    pageInfo {
      startCursor
      endCursor
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

{/* prettier-ignore */}
```json filename="Result one"
{
  "persons" {
    "items": [
      { "name": "Barry", "age": 57 },
      { "name": "Pablo", "age": 71 },
    ],
    "pageInfo": {
      "startCursor": "MxhcdoP9CVBhY",
      "endCursor": "McSDfVIiLka==",
      "hasPreviousPage": true,
      "hasNextPage": false,
    },
    "totalCount": 4,
  }
}
```

</div>

To paginate backwards, pass `pageInfo.startCursor` from the previous request as the `before` option in the next request.

<div className="code-columns">
```graphql filename="Query three" {6}
query {
  persons(
    orderBy: "age",
    orderDirection: "asc",
    limit: 2,
    before: "MxhcdoP9CVBhY"
  ) {
    items {
      name
      age
    }
    pageInfo {
      startCursor
      endCursor
      hasPreviousPage
      hasNextPage
    }
    totalCount
  }
}
```

{/* prettier-ignore */}
```json filename="Result three"
{
  "persons" {
    "items": [
      { "name": "Lucile", "age": 32 },
    ],
    "pageInfo": {
      "startCursor": "Mxhc3NDb3JlLTA=",
      "endCursor": "Mxhc3NDb3JlLTA=",
      "hasPreviousPage": true,
      "hasNextPage": true,
    },
    "totalCount": 4,
  }
}
```

</div>

## Relationship fields

<Callout type="info">
  [Read more](/docs/schema#relationships) about how to define relationships in
  your schema.
</Callout>

The GraphQL schema includes a relationship field for each `one` or `many` relation defined in your schema. One-to-many fields are very similar to the top-level plural query field, except they are automatically filtered by the parent row ID.

<div className="code-columns">
```ts filename="ponder.schema.ts"
import { onchainTable, relations } from "ponder";

export const pet = onchainTable("pet", (t) => ({
  id: t.text().primaryKey(),
  name: t.text().notNull(),
  ownerId: t.integer().notNull(),
}));

export const petRelations = relations(pet, ({ one }) => ({
  owner: one(person, { fields: [pet.ownerId], references: [person.id] }),
}));

export const person = onchainTable("person", (t) => ({
  id: t.integer().primaryKey(),
}));

export const personRelations = relations(person, ({ many }) => ({
  dogs: many(pet),
}));
```

{/* prettier-ignore */}
```graphql filename="Generated schema"
type pet {
  id: String!
  name: String!
  ownerId: Int!
  owner: person!
}

type person {
  id: Int!
  pets(
    # Has { ownerId: person.id } applied
    where: petFilter, 
    orderBy: String,
    orderDirection: String,
    before: String,
    after: String,
    limit: Int,
    timestamp: Int,
  ): petPage!
}
```

</div>

## Performance tips

Here are a few tips for speeding up slow GraphQL queries.

1. **Create database indexes**: Create indexes to speed up filters, joins, and sort conditions. Keep in mind that relations **do not** automatically create indexes. [Read more](/docs/schema#indexes).
2. **Enable horizontal scaling**: If the GraphQL API is struggling to keep up with request volume, consider spreading the load across multiple instances. [Read more](/docs/production/horizontal-scaling).
3. **Limit query depth**: Each layer of depth in a GraphQL query introduces at least one additional sequential database query. Avoid queries that are more than 2 layers deep.
4. **Use pagination**: Use cursor-based pagination to fetch records in smaller, more manageable chunks. This can help reduce the load on the database.

---
title: "Accounts"
description: "Learn how to index accounts in a Ponder app"
---

import { Callout, Steps } from "nextra/components";

# Accounts

Account indexing is useful for activity that is not associated with a specific contract, like transactions and native transfers to and from an address. The key difference between `contracts` and `accounts` in `ponder.config.ts` is that accounts do not have an ABI.

<Callout type="info">
  The standard Ethereum RPC does not support filtering for transactions & native
  transfers. So, account indexing uses a block-by-block approach which is often
  slower than log indexing.
</Callout>

## Quick example

In this example, we'll index transactions sent by the [Beaver](https://beaverbuild.org/) block builder account.

<Steps>

### Add an account

Add the network, address, and start block to the `accounts` field in `ponder.config.ts`.

```ts filename="ponder.config.ts"
import { createConfig } from "ponder";

export default createConfig({
  // ... more config
  accounts: {
    BeaverBuild: {
      network: "mainnet",
      address: "0x95222290DD7278Aa3Ddd389Cc1E1d165CC4BAfe5",
      startBlock: 20000000,
    },
  },
});
```

### Register indexing functions

Register an indexing function for the `transaction:from` event. The framework will fetch all transactions where `transaction.from` matches the account address, then process each one using your indexing function.

```ts filename="src/index.ts" {4}
import { ponder } from "ponder:registry";
import { transactions } from "ponder:schema";

ponder.on("BeaverBuild:transaction:from", async ({ event, context }) => {
  await context.db.insert(transactions).values({
    from: event.transaction.from,
    to: event.transaction.to,
    value: event.transaction.value,
    gasUsed: event.transactionReceipt.gasUsed,
    // ... more fields
  });
});
```

Account indexing also supports the `transaction:to`, `transfer:from`, and `transfer:to` events. [Read more](/docs/api-reference/config#accounts) about event types.

</Steps>

## Account name

Every account must have a unique name, provided as a key to the `accounts` object. Names must be unique across accounts, contracts, and block intervals.

```ts filename="ponder.config.ts" {9}
import { createConfig } from "ponder";
import { http } from "viem";

export default createConfig({
  networks: {
    mainnet: { chainId: 1, transport: http(process.env.PONDER_RPC_URL_1) },
  },
  accounts: {
    BeaverBuild: {
      network: "mainnet",
      address: "0x95222290DD7278Aa3Ddd389Cc1E1d165CC4BAfe5",
      startBlock: 12439123,
    },
  },
});
```

## Network

The `network` option for accounts works the same way as it does for contracts. [Read more](/docs/contracts-and-networks#network).

## Address

The `address` option for accounts works the same way as it does for contracts. You can provide a single address, a list of addresses, or an address factory. You can also specify network-specific overrides. [Read more](/docs/contracts-and-networks#address).

## Block range

The `startBlock` and `endBlock` options for accounts work the same way as it does for contracts. [Read more](/docs/contracts-and-networks#block-range).

---
title: "Why Ponder"
description: "A few notes on why we built Ponder"
---

import { Benchmarks } from "@/components/Benchmarks";

# Why Ponder

**Ponder is an open-source backend framework for crypto apps.**

With Ponder, you can rapidly build & deploy an API that serves custom data from smart contracts on any EVM blockchain.

## Most apps need a backend

Many developers have quietly accepted that you need traditional backend web services to build great crypto apps ‚Äì particularly for indexing.

The standard RPC, subgraphs, and out-of-the-box API endpoints are great for getting started, but fall short as applications mature and new requirements appear. When this happens, developers often roll their own web backend, which gives them the flexibility to write custom server-side code.

Unfortunately, engineering teams across the industry reinvent the wheel on common problems (reorgs, RPC error handling, etc) in closed-source repositories where best practices remain siloed.

We built Ponder because **this is a framework-shaped problem**.

## Local development

It‚Äôs so hard to run a subgraph locally that devs often deploy to the hosted service just to run their code. This creates long feedback loops and errors that are painful to debug.

Ponder is designed from the ground up for local development. The dev server has hot reloading for every file in your project and descriptive error logs that keep you unblocked.

![Ponder dev server hot reloading](/hot-reloading.gif)

Ponder‚Äôs type safety and editor autocomplete is very thorough, and works without any codegen or build step. If your code passes the type checker, it will usually run without error.

## Focus on web developers

Ponder is built for web & mobile application developers. If you understand the basics of Ethereum and can write some TypeScript, you‚Äôll be productive with Ponder in a matter of minutes. (So, data analysts, protocol developers, and researchers can use Ponder too.)

Your code runs in a JavaScript runtime (Node.js) where you can import NPM packages, make HTTP requests, and connect to databases. This makes it easy to do things that are painful in constrained environments like WebAssembly sandboxes, SQL engines, and EVM runtimes.

## Performance

Long feedback loops are the kiss of death for developer productivity, and unfortunately they're commonplace in blockchain indexing tools.

Ponder is fast and lean. In our initial benchmarks, Ponder indexed an ERC20 contract ~10x faster than the Graph Node from a cold start and 15x faster fully cached.

<Benchmarks flat className="mt-6"/>

Ponder also used fewer resources ‚Äî 35x less disk space and 35% fewer RPC credits.

## Get started

- [Quickstart](/docs/getting-started/new-project)
- [GitHub repo ‚Üó](https://github.com/ponder-sh/ponder)
- [Telegram chat ‚Üó](https://t.me/ponder_sh)
- [Twitter ‚Üó](https://x.com/ponder_sh)
